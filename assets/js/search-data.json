{
  
    
        "post0": {
            "title": "Recuadros para mapas en Geopandas",
            "content": "Introducci&#243;n . Con la reciente publicaci√≥n de los resultados del censo 2020 de INEGI varios usuarios han estado presentando algunas gr√°ficas en redes sociales con los principales resultados. Una de las visualizaciones m√°s populares son los mapas coropl√©ticos, especialmente a nivel municipal. Una ventaja de estos mapas es que nos permiten tener el panorama general de todo el pa√≠s e incluso detectar a grandes rasgos algunos patrones regionales. Por ejemplo, ac√° @claudiodanielpc nos muestra el hacinamiento en los hogares: Siguiendo con los microdatos del #Censo2020Mx, hice este mapa en #rstats sobre el hacinamiento en cada municipio.Gracias al Dr. @SantaellaJulio y al gran equipo del @INEGI_INFORMA por brindarnos informaci√≥n para el an√°lisis de los problemas de nuestro pa√≠s. pic.twitter.com/K9zhJkSmEt . &mdash; Claudio Daniel Pacheco Castro (@claudiodanielpc) March 22, 2021 . Sin embargo, un inconveniente es que hay casos de regiones donde hay un gran n√∫mero de municipios en una superficie peque√±a lo que dificulta la lectura de la informaci√≥n. Un caso com√∫n en M√©xico es el √°rea compuesta por los estados de Oaxaca, Puebla, Chiapas, Veracruz y Estado de M√©xico que contienen 1248 municipios, poco m√°s de la mitad del total de 2469 municipios. Muchos mapas se vuelven dif√≠cil de ver en esta zona. Por ejemplo: . . Para tratar de hacer m√°s claras este tipo de visualizaciones podemos agregar uno o varios recuadros con acercamiento (zoom) a los resultados de estas zonas, tal como lo hace el mapa del ejemplo. Si bien eso no garantiza que toda la informaci√≥n se entender√° mejor, al menos puede ayudar en ciertas √°reas. En esta entrada veremos c√≥mo hacer varios tipos de recuadros para mapas en Python usando Geopandas y Matplotlib. . Empecemos importando las librer√≠as necesarias. . import os import sys import geopandas as gpd import matplotlib.pyplot as plt import pandas as pd import requests import matplotlib_scalebar from matplotlib_scalebar.scalebar import ScaleBar print(&#39;Python&#39;, sys.version) print(pd.__name__, pd.__version__) print(gpd.__name__, gpd.__version__) print(requests.__name__, requests.__version__) print(plt.matplotlib.__name__, plt.matplotlib.__version__) print(matplotlib_scalebar.__name__, matplotlib_scalebar.__version__) . Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)] pandas 1.1.3 geopandas 0.8.1 requests 2.24.0 matplotlib 3.3.2 matplotlib_scalebar 0.7.2 . Datos . Voy a usar una versi√≥n del mapa de M√©xico algo simplificada que pesa relativamente poco. Este shapefile puede descargarse aqu√≠. . Tip: la versi√≥n m√°s reciente de la cartograf√≠a de los municipios de M√©xico puede descargarse desde el Marco Geoestad√≠stico Nacional de INEGI. . Leemos el archivo, asignamos la clave municipal de INEGI como el √≠ndice del GeoDataFrame y adem√°s reproyectamos las coordenadas usando el sistema de coordenadas Mexico ITRF92 / UTM zone 12N . mx = gpd.read_file(&#39;mapa_mexico/&#39;) .set_index(&#39;CLAVE&#39;) .to_crs(epsg=4485) mx.head() . NOM_MUN NOMEDO CVE_EDO CVE_MUNI Area geometry . CLAVE . 02004 Tijuana | Baja California | 02 | 004 | 1122.661145 | POLYGON ((-73565.018 3602427.487, -73564.403 3... | . 02003 Tecate | Baja California | 02 | 003 | 3670.991923 | POLYGON ((-38995.078 3617846.589, -31557.921 3... | . 02002 Mexicali | Baja California | 02 | 002 | 13119.275713 | POLYGON ((48160.716 3621731.593, 58570.990 362... | . 02005 Playas de Rosarito | Baja California | 02 | 005 | 517.120801 | POLYGON ((-70946.724 3594803.753, -70966.034 3... | . 26055 San Luis Rio Colorado | Sonora | 26 | 055 | 9033.770278 | POLYGON ((127160.493 3587762.823, 127099.688 3... | . Al GeoDataFrame anterior vamos a a√±adirle datos para que podamos graficar un mapa coropl√©tico. Usaremos la API de DataM√©xico para obtener los datos del √çndice de Complejidad Econ√≥mica (ECI). La propia definici√≥n del ECI de DataMexico es: . El √çndice de Complejidad Econ√≥mica (ECI) mide las capacidades productivas de una localidad (e.g. estado o municipalidad) a partir de la presencia de actividades (e.g. empleo, industrias o exportaciones) en esa y otras localidades. La complejidad econ√≥mica de una localidad predice su nivel de ingreso, crecimiento econ√≥mico, desigualdad, y emisiones de gases de efecto invernadero. . En general, un ECI m√°s alto indica un mayor nivel de sofisticaci√≥n en los productos que se producen en un municipio. As√≠ se ven los datos: . url = &#39;https://api.datamexico.org/tesseract/cubes/complexity_eci/aggregate.jsonrecords?cuts%5B%5D=Latest.Latest.Latest.1&amp;drilldowns%5B%5D=Geography+Municipality.Geography.Municipality&amp;drilldowns%5B%5D=Date+Day.Date.Year&amp;measures%5B%5D=ECI&amp;parents=false&amp;sparse=false&#39; data_eci = requests.get(url).json() eci = pd.DataFrame(data_eci[&#39;data&#39;]) .assign(CLAVE=lambda x: x[&#39;Municipality ID&#39;].astype(str).str.zfill(5)) .set_index(&#39;CLAVE&#39;) eci.head() . Municipality ID Municipality Year ECI . CLAVE . 01001 1001 | Aguascalientes | 2020 | 2.976280 | . 01002 1002 | Asientos | 2020 | -0.430667 | . 01003 1003 | Calvillo | 2020 | 0.420862 | . 01004 1004 | Cos√≠o | 2020 | -0.464407 | . 01005 1005 | Jes√∫s Mar√≠a | 2020 | 3.049664 | . El √≠ndice est√° estandarizado con una media de 0 y varianza de 1 y tiene un rango entre -1.4 y 4.9. . eci[&#39;ECI&#39;].describe() . count 2.142000e+03 mean 7.507756e-10 std 1.000000e+00 min -1.399253e+00 25% -6.253233e-01 50% -2.969113e-01 75% 2.492735e-01 max 4.901706e+00 Name: ECI, dtype: float64 . Revisamos su distribuci√≥n: . eci[&#39;ECI&#39;].hist(bins=100) . &lt;AxesSubplot:&gt; . Ahora anexamos los datos del ECI al GeoDataFrame: . mx = mx.join(eci, how=&#39;left&#39;) mx.head() . NOM_MUN NOMEDO CVE_EDO CVE_MUNI Area geometry Municipality ID Municipality Year ECI . CLAVE . 01001 Aguascalientes | Aguascalientes | 01 | 001 | 1168.762384 | POLYGON ((1416489.577 2467700.472, 1417908.226... | 1001.0 | Aguascalientes | 2020.0 | 2.976280 | . 01002 Asientos | Aguascalientes | 01 | 002 | 547.762077 | POLYGON ((1417043.958 2491681.240, 1417408.488... | 1002.0 | Asientos | 2020.0 | -0.430667 | . 01003 Calvillo | Aguascalientes | 01 | 003 | 931.300088 | POLYGON ((1347882.273 2454901.097, 1348002.307... | 1003.0 | Calvillo | 2020.0 | 0.420862 | . 01004 Cosio | Aguascalientes | 01 | 004 | 128.907513 | POLYGON ((1397788.297 2509816.078, 1398009.089... | 1004.0 | Cos√≠o | 2020.0 | -0.464407 | . 01005 Jesus Maria | Aguascalientes | 01 | 005 | 499.207990 | POLYGON ((1388272.165 2462097.533, 1389832.232... | 1005.0 | Jes√∫s Mar√≠a | 2020.0 | 3.049664 | . Creamos un par de GeoDataFrames que nos servir√°n m√°s adelante: . oax contiene los datos solo para el estado de Oaxaca | edos es un GeoDataFrame con los pol√≠gonos de los estados del pa√≠s. | . oax = mx.query(&#39;CVE_EDO==&quot;20&quot;&#39;) edos = mx.dissolve(by=&#39;CVE_EDO&#39;) . Y ahora visualicemos el ECI con un esquema de cortes por quintiles: . fig, ax = plt.subplots() mx.plot(column=&#39;ECI&#39;, legend=True, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;, ax=ax) fig.set_size_inches(12, 8) . Como se puede ver, algunas zonas del centro y sur del pa√≠s son dif√≠ciles de distinguir por el gran n√∫mero de municipios que hay. . Recuadro de acercamiento . Vamos a a√±adir un recuadro de acercamiento o detalle a la zona sur, se√±alando principalmente los municipios del estado de Oaxaca. Para eso usaremos la funci√≥n inset_axes de Matplotlib. Esta funci√≥n nos permite a√±adir un nuevo objeto axes a nuestra gr√°fica en cualquier parte del gr√°fico. La funci√≥n recibe una lista con 4 valores que son: $[x, y, w, h]$: . $x$: posici√≥n en el eje x de la esquina inferior izquierda del recuadro | $y$: posici√≥n en el eje y de la esquina inferior izquierda del recuadro | $w$: ancho del recuadro | $h$: altura del recuadro | . Todos estos valores vienen expresados como proporci√≥n del tama√±o de la gr√°fica (proporci√≥n del ancho para el eje x, proporci√≥n del alto para el eje y). Veamos un ejemplo: . fig, ax = plt.subplots() axins = ax.inset_axes([1.1, 0.5, 0.4, 0.4]) axins.set(xlim=(0.5, 0.7), ylim=(0.4, 0.6)) ax.indicate_inset_zoom(axins) . (&lt;matplotlib.patches.Rectangle at 0x2f7a3bf22e0&gt;, (&lt;matplotlib.patches.ConnectionPatch at 0x2f7a3c269d0&gt;, &lt;matplotlib.patches.ConnectionPatch at 0x2f7a3c26d30&gt;, &lt;matplotlib.patches.ConnectionPatch at 0x2f7a3c26fa0&gt;, &lt;matplotlib.patches.ConnectionPatch at 0x2f7a0951550&gt;)) . Lo que hicimos fue a√±adir una figura (fig) y un objeto axes principal (ax). Luego a√±adimos el recuadro axins y limitamos el rango del eje $x$ e $y$ en los que se enfoca el recuadro. Por √∫ltimo, le indicamos al recuadro cu√°l es la gr√°fica principal sobre la que esta haciendo el zoom. Lo que falta es dibujar sobre los objetos ax y axins. . x = [0, 0.5, 0.6, 0.8] y = [0, 0.4, 0.5, 0.3] ax.plot(x, y, color=&#39;C0&#39;) axins.plot(x, y, color=&#39;C0&#39;) fig . Aunque es relativamente f√°cil a√±adir un recuadro a una gr√°fica, es un poco m√°s dif√≠cil a√±adir el recuadro a un mapa. La dificultad adicional est√° en que en el resultado final los par√°metros $x$, $y$, $w$ y $h$ no se comportan exactamente como ser√≠a esperado, sino que por alg√∫n motivo el recuadro queda en una posici√≥n un poco diferente. No podr√≠a asegurarlo, pero me parece que esto pasa porque al graficar un mapa Matplotlib modifica el tama√±o de la gr√°fica y su relaci√≥n de aspecto para ajustarlo a la informaci√≥n geogr√°fica. La soluci√≥n (muy poco satisfactoria) es jugar con varios valores de $x$, $y$, $w$ y $h$ hasta que la posici√≥n sea la adecuada. . En el siguiente ejemplo vamos a acercarnos al estado de Oaxaca con un recuadro usando los par√°metros $x=0.82, y=0.05, w=0.9, h=0.9$ y poniendo como l√≠mite al eje x el rango (1820000, 2350000) y al eje y el rango (1780000, 2150000). Los valores (y su unidad de medida) de los ejes X e Y vienen dadas por el sistema de coordenadas geogr√°ficas que usamos. . fig, ax = plt.subplots() # A√±ade recuadro axins = ax.inset_axes([0.82, 0.05, 0.9, 0.9]) # Gr√°fica principal mx.plot(column=&#39;ECI&#39;, legend=True, ax=ax, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;, legend_kwds={&#39;loc&#39;: &#39;lower left&#39;}) mx.boundary.plot(lw=0.05, color=&#39;k&#39;, ax=ax) # Gr√°fica recuadro mx.plot(column=&#39;ECI&#39;, legend=False, ax=axins, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;) mx.boundary.plot(lw=0.25, color=&#39;k&#39;, ax=axins) edos.boundary.plot(lw=1, color=&#39;red&#39;, ax=axins) # limita √°rea a mostrar axins.set(ylabel=&#39;&#39;, xlabel=&#39;&#39;, xlim=(1820000, 2350000), ylim=(1780000, 2150000), xticks=[], yticks=[]) # Establece l√≠neas del recuadro a la gr√°fica principal ax.indicate_inset_zoom(axins) # Tama√±o de la gr√°fica final fig.set_size_inches(12, 8) . El acercamiento resulta bastante bueno, ahora es posible identificar mejor los valores del ECI para el estado de Oaxaca y otros vecinos. Podemos a√±adir un segundo recuadro para ver los municipios del industrial estado de Guanajuato. El proceso es el mismo que el anterior, aunque ahora demorar√° m√°s porque debe graficar m√°s elementos. . fig, ax = plt.subplots() # A√±ade recuadro 1 axins = ax.inset_axes([0.86, 0.05, 0.9, 0.9]) # A√±ade recuadro 2 axins2 = ax.inset_axes([0.2, -0.5, 0.5, 0.5]) # Gr√°fica principal mx.plot(column=&#39;ECI&#39;, legend=True, ax=ax, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;, legend_kwds={&#39;loc&#39;: &#39;lower left&#39;}) mx.boundary.plot(lw=0.05, color=&#39;k&#39;, ax=ax) # Gr√°fica recuadro 1 mx.plot(column=&#39;ECI&#39;, legend=False, ax=axins, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;) mx.boundary.plot(lw=0.25, color=&#39;k&#39;, ax=axins) edos.boundary.plot(lw=1, color=&#39;red&#39;, ax=axins) # Gr√°fica recuadro 2 mx.plot(column=&#39;ECI&#39;, legend=False, ax=axins2, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;) mx.boundary.plot(lw=0.25, color=&#39;k&#39;, ax=axins2) edos.boundary.plot(lw=1, color=&#39;red&#39;, ax=axins2) # limita √°rea a mostrar recuadro 1 y 2 axins.set(ylabel=&#39;&#39;, xlabel=&#39;&#39;, xlim=(1820000, 2350000), ylim=(1780000, 2150000), xticks=[], yticks=[], title=&#39;Oaxaca&#39;) axins2.set(ylabel=&#39;&#39;, xlabel=&#39;&#39;, xlim=(1425000, 1680000), ylim=(2229203, 2453767), xticks=[], yticks=[], title=&#39;Guanajuato&#39;) # Elimina marco de la gr√°fica principal ax.set_axis_off() # Establece l√≠neas de los recuadros a la gr√°fica principal ax.indicate_inset_zoom(axins) ax.indicate_inset_zoom(axins2) # Tama√±o de la gr√°fica final fig.set_size_inches(12, 8) . Es notable la diferencia en la complejidad entre los municipios de Guanajuato y Oaxaca. . El peque√±o recuadro al interior que se√±ala el √°rea del mapa principal que se est√° se√±alando no se nota mucho porque se confunde con el color de los pol√≠gonos. Para evitar eso, podemos recolorear el borde de los recuadros para que sea posible asociarlos usando el color. Esta idea la vi en un mapa creado por @ElenoAM ü§Ø y me pareci√≥ incluso m√°s limpia que tener varias l√≠neas indicando el zoom. Mapa del fracaso de la pol√≠tica de suelo y de vivienda de @FelipeCalderon y de @VicenteFoxQue.Desarrollos inmobiliarios periurbanos, mal ubicados, sin servicios, empleo... pic.twitter.com/dvqZRi8euR . &mdash; Adri√°n (@ElenoAM) March 11, 2021 . Veamos ahora c√≥mo queda tras quitar las l√≠neas y ponerle colores al borde de los recuadros. . fig, ax = plt.subplots() # A√±ade recuadro 1 axins = ax.inset_axes([0.86, 0.05, 0.9, 0.9]) # A√±ade recuadro 2 axins2 = ax.inset_axes([0.2, -0.5, 0.5, 0.5]) # Gr√°fica principal mx.plot(column=&#39;ECI&#39;, legend=True, ax=ax, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;, legend_kwds={&#39;loc&#39;: &#39;lower left&#39;}) mx.boundary.plot(lw=0.05, color=&#39;k&#39;, ax=ax) # Gr√°fica recuadro 1 mx.plot(column=&#39;ECI&#39;, legend=False, ax=axins, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;) mx.boundary.plot(lw=0.25, color=&#39;k&#39;, ax=axins) edos.boundary.plot(lw=1, color=&#39;red&#39;, ax=axins) # Gr√°fica recuadro 2 mx.plot(column=&#39;ECI&#39;, legend=False, ax=axins2, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;) mx.boundary.plot(lw=0.25, color=&#39;k&#39;, ax=axins2) edos.boundary.plot(lw=1, color=&#39;red&#39;, ax=axins2) # limita √°rea a mostrar recuadro 1 y 2 axins.set(ylabel=&#39;&#39;, xlabel=&#39;&#39;, xlim=(1820000, 2350000), ylim=(1780000, 2150000), xticks=[], yticks=[], title=&#39;Oaxaca&#39;) axins2.set(ylabel=&#39;&#39;, xlabel=&#39;&#39;, xlim=(1425000, 1680000), ylim=(2229203, 2453767), xticks=[], yticks=[], title=&#39;Guanajuato&#39;) # Elimina marco de la gr√°fica principal ax.set_axis_off() # Establece l√≠neas de los recuadros a la gr√°fica principal ax.indicate_inset_zoom(axins) ax.indicate_inset_zoom(axins2) # Parametros para cambiar colores color_insets = [&#39;red&#39;, &#39;blue&#39;] color_index = 0 # colorea los cuadros interiores for p in ax.patches: if isinstance(p, plt.matplotlib.patches.Rectangle): p.set_edgecolor(color_insets[color_index]) p.set_linewidth(2) color_index += 1 else: # Esconde las l√≠neas hacia la gr√°fica principal p.set_visible(False) # Colorea el marco del recuadro 1 y aumenta grosor de l√≠nea for sp in axins.spines.values(): sp.set_color(color_insets[0]) sp.set_linewidth(2) # Colorea el marco del recuadro 2 y aumenta grosor de l√≠nea for sp in axins2.spines.values(): sp.set_color(color_insets[1]) sp.set_linewidth(2) # Tama√±o final fig.set_size_inches(12, 8) . Ahora es m√°s f√°cil identificar el √°rea que se est√° acercando. . Recuadro de contexto . En un recuadro de contexto el mapa principal corresponde a la regi√≥n que vamos a analizar con detalle y usamos el recuadro para resaltar la posici√≥n de esa regi√≥n con respecto al pa√≠s. Para lograr este efecto no usamos la funci√≥n ax.inset_axes(), sino una muy parecida que es fig.add_axes() y recibe los mismos argumentos $x, y, w, h$. La diferencia es que ahora no tendremos las l√≠neas desde el recuadro hasta el mapa principal. . fig, ax = plt.subplots() # Mapa principal oax.plot(column=&#39;ECI&#39;, legend=True, scheme=&#39;quantiles&#39;, k=5, cmap=&#39;viridis_r&#39;, ax=ax) # Borde de los municipios oax.boundary.plot(linewidth=0.5, color=&#39;gray&#39;, ax=ax) # Inserta recuadro ax_mex = fig.add_axes([0.91, 0.11, 0.35, 0.35], ) # Dibuja los estados del pa√≠s en el recuadro edos.boundary.plot(color=&#39;gray&#39;, ax=ax_mex) # Resalta Oaxaca con el color rojo edos.query(&#39;CVE_EDO==&quot;20&quot;&#39;).plot(color=&#39;red&#39;, ax=ax_mex) # Establece tama√±o final fig.set_size_inches(12, 8) . Escalas . Cuando graficamos mapas con distintos niveles de acercamiento/alejamiento es importante acompa√±ar cada mapa con una barra de escala que nos permita saber c√≥mo comparar longitudes. Para Matplotlib existe la excelente librer√≠a matplotlib-scalebar para agregar estas escalas y afortunadamente funciona bien con mapas de Geopandas. A continuaci√≥n a√±adimos las escalas para cada mapa. . ax.set(xticks=[], yticks=[], title=&#39;Oaxaca&#39;) ax_mex.set(xticks=[], yticks=[], title=&#39;M√©xico&#39;) # Barras de escala scalebar_oax = ScaleBar(1, &quot;m&quot;, length_fraction=0.2, location=&#39;lower left&#39;, ) ax.add_artist(scalebar_oax) scalebar_mex = ScaleBar(1, &quot;m&quot;, length_fraction=0.25, location=&#39;lower left&#39;) ax_mex.add_artist(scalebar_mex) fig . De esta forma podemos reconocer mejor las dimensiones de Oaxaca y sus municipios con respecto a todo el pa√≠s. . Recuadro de &#225;reas no contiguas . Este tipo de recuadro sirve para mostrar juntas √°reas que no est√°n cerca o es muy dif√≠cil ver juntas en su ubicaci√≥n normal. El primer caso que viene a mi cabeza es el del departamento de San Andr√©s y Providencia en Colombia üü®üü®üü¶üü•. San Andr√©s y Providencia son unas diminutas islas ubicadas a 774 km del noreste de Colombia y que conforman uno de los 32 departamentos del pa√≠s. En los mapas de divisi√≥n pol√≠tica-administrativa del pa√≠s estas islas siempre aparecen como recuadros al lado de la parte continental, con una escala mucho mayor para poder ser visibles. . Para visualizarlas usemos este mapa de Colombia con la divisi√≥n por departamentos que tambi√©n puede descargarse desde el Marco Geostad√≠stico Nacional. Usaremos el sistema de coordenadas MAGNA-SIRGAS / Colombia Bogota zone. . col = gpd.read_file(&#39;mapa_colombia/&#39;).to_crs(epsg=3116) col.head() . DPTO_CCDGO DPTO_CNMBR DPTO_NANO_ DPTO_CACTO DPTO_NANO SHAPE_AREA SHAPE_LEN geometry . 0 18 | CAQUET√Å | 1981 | Ley 78 del 29 de Diciembre de 1981 | 2020 | 7.318485 | 21.384287 | POLYGON ((909199.769 818940.314, 909214.572 81... | . 1 19 | CAUCA | 1857 | 15 de junio de 1857 | 2020 | 2.534419 | 13.950263 | POLYGON ((735237.006 860162.569, 735286.223 86... | . 2 86 | PUTUMAYO | 1991 | Articulo 309 Constitucion Politica de 1991 | 2020 | 2.107965 | 12.707922 | POLYGON ((711344.106 654182.557, 711400.239 65... | . 3 76 | VALLE DEL CAUCA | 1910 | Decreto No 340 de 16 de Abril de 1910 | 2020 | 1.679487 | 12.650870 | MULTIPOLYGON (((777973.333 1049936.014, 777964... | . 4 94 | GUAIN√çA | 1991 | Articulo 309 Constitucion Politica de 1991 | 2020 | 5.747937 | 21.179051 | POLYGON ((1712400.898 927096.060, 1712774.632 ... | . Al graficar el mapa del pa√≠s a duras penas podremos notar las islas en la parte superior derecha. . fig, ax = plt.subplots() col.plot(ax=ax) fig.set_size_inches(10, 10) . Para hacer un t√≠pico mapa pol√≠tico administrativo, vamos a a√±adir dos objetos axes con fig.add_axes() en los que graficaremos a cada isla. Para encontrar las coordenadas de las islas lo mejor es usar el mapa de http://epsg.io/map#srs=3116&amp;x&amp;y&amp;z=10&amp;layer=streets. Tambi√©n agregamos las barras de escala para dimensionar mejor lo peque√±as que son. . fig, ax = plt.subplots() # A√±ade ax para San Andr√©s ax_san = fig.add_axes([0.25, 0.75, 0.05, 0.1]) # A√±ade ax para Providencia ax_prov = fig.add_axes([0.29, 0.77, 0.08, 0.08]) # Grafica Parte continental col.plot(ax=ax) # Grafica San Andr√©s col.plot(ax=ax_san) # Grafica Providencia col.plot(ax=ax_prov) # Limita los valores del eje x e y para cada gr√°fica ax.set(ylim=(0, 1_900_000), xlim=(400_000, 1_850_000), yticks=[], xticks=[]) ax_san.set(ylim=(1_883_000, 1_902_000), xlim=(163_000, 172_000), yticks=[], xticks=[]) ax_prov.set(ylim=(1_975_000, 1_990_000), xlim=(204_044, 211_100), yticks=[], xticks=[]) # T√≠tulos de las gr√°ficas ax.set_title(&#39;Colombia&#39;, fontsize=20) ax_san.set_title(&#39;San n Andr√©s&#39;, fontsize=7) ax_prov.set_title(&#39;Providencia&#39;, fontsize=7) # A√±ade barras de escala scalebar_col = ScaleBar(1, &quot;m&quot;, length_fraction=0.2, location=&#39;lower left&#39;, ) ax.add_artist(scalebar_col) scalebar_san = ScaleBar(1, &quot;m&quot;, length_fraction=1, location=&#39;upper center&#39;, font_properties={&#39;size&#39;: 7}) ax_san.add_artist(scalebar_san) scalebar_prov = ScaleBar(1, &quot;m&quot;, length_fraction=0.8, location=&#39;upper center&#39;, box_alpha=0, font_properties={&#39;size&#39;: 7}) ax_prov.add_artist(scalebar_prov) # Tama√±o final de la gr√°fica fig.set_size_inches(10, 10) .",
            "url": "http://blog.jjsantoso.com/zoom-mapas-geopandas/",
            "relUrl": "/zoom-mapas-geopandas/",
            "date": " ‚Ä¢ Mar 23, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Etiquetado de variables y valores en las encuestas de INEGI usando Python",
            "content": "Elaborado por Juan Javier Santos Ochoa (@jjsantoso) . Introducci&#243;n . Hace poco me toc√≥ trabajar con los datos de una encuesta de INEGI y us√© Python para hacer el an√°lisis descriptivo. Quienes trabajamos con datos del INEGI hemos visto que es usual que los archivos de datos abiertos vengan en varias carpetas que contienen tanto los datos como los metadatos e informaci√≥n adicional sobre la encuesta. Por ejemplo, si descargamos los datos para la Encuesta Nacional de Seguridad P√∫blica Urbana (ENSU) veremos que vienen 3 carpetas, cada una corresponde a una secci√≥n de la encuesta: . Note: Los datos se pueden descargar directamente de la p√°gina de INEGI, pero aqu√≠ dejo una copia de los que yo us√© para este tutorial. Descargar datos . conjunto_de_datos_VIV_ENSU_12_2020: Cuestionario sociodemogr√°fico secci√≥n I y II | conjunto_de_datos_CS_ENSU_12_2020: Cuestionario sociodemogr√°fico secci√≥n III | conjunto_de_datos_CB_ENSU_12_2020: Cuestionario principal de la encuesta secci√≥n I, II, III y IV | . Si vemos al interior de uno de estos m√≥dulos, la estructura incluye las siguientes carpetas: . Cat√°logos: tiene los cat√°logos para cada variable en el cuestionario | Conjunto de datos: tiene los datos principales de la encuesta | Diccionario de datos: el nombre e informaci√≥n de cada variable | Metadatos: tiene informaci√≥n de la encuesta. | Modelo entidad relaci√≥n: es un diagrama que muestra c√≥mo se relacionan los diferentes conjuntos de datos. | . . Si echamos un vistazo r√°pido a los datos en Excel (conjunto_de_datos/conjunto_de_datos_CB_ENSU_12_2020.csv) veremos que la mayor parte de las variables viene codificada. Solo con este archivo no podemos saber qu√© es cada columna y cu√°les es el significado de sus valores. Nos hace falta el diccionario de variables y los cat√°logos para poder interpretarlas. . . En el archivo diccionario_de_datos/diccionario_de_datos_CB_ENSU_12_2020.csv tenemos cu√°l es el texto de cada pregunta. De ah√≠ sabemos que, por ejemplo, la pregunta BP1_1 es &quot;Percepci√≥n de seguridad en la ciudad&quot;. Estos valores se conocen como etiquetas de las variables. . Por otro lado, dentro de la carpeta catalogos viene un archivo csv por cada variable del conjunto de datos. . . Este archivo nos dice c√≥mo debemos transformar los valores num√©ricos de las categor√≠as por sus valores de texto. Por ejemplo, si abrimos el archivo &quot;BP1_1.csv&quot; su contenido nos muestra que para la variable BP1_1 debemos interpretar que un 1 corresponde a la categor√≠as &quot;seguro?&quot;, el 2 corresponde a &quot;inseguro?&quot; y el 9 a &quot;No sabe/No responde&quot;. Estos valores se conocen como etiquetas de los valores. . Note: Las etiquetas de valores tiene sentido para variables categ√≥ricas, es decir las que tienen pocos valores nominales. Para variables num√©ricas o puramente de texto no es necesario usar etiquetas de valores. . . Es evidente que para manejar una encuesta es fundamental conocer las etiquetas de las variables y sus valores. Ser√≠a mucho m√°s f√°cil si estas etiquetas estuvieran incluidas en el mismo archivo junto con los datos, pero como est√°n en formato .csv no es posible guadar esa informaci√≥n en un solo archivo y por tanto, termina repartida en muchos. Entonces, nuestro objetivo es integrar el diccionario y el cat√°logo a los datos para que sea m√°s f√°cil hacer nuestro an√°lisis. Queremos que en las tablas o gr√°ficas que hagamos, las variables categ√≥ricas aparezcan como texto, en lugar de los valores num√©ricos que asign√≥ INEGI. De igual forma, nos gustar√≠a que en lugar de aparecer el nombre de la variable como en la base de datos, aparezca su descripci√≥n. Para lograr esto usaremos objetos tipo diccionario nativos de Python y dataframes de Pandas. . Tip: Otros formatos de datos, como por ejemplo los archivos .dta de Stata o .sav de SPSS s√≠ permiten guardar esas etiquetas junto con los datos, sin embargo, esos no son formatos de datos abiertos que sean f√°cilmente accesible. En algunos casos, como en la ENOE, INEGI tambi√©n publica archivos .dta y .sav. . Datos . Primero, vamos a importar las librer√≠as necesarias. . import glob import sys import pandas as pd print(&#39;Python&#39;, sys.version) print(pd.__name__, pd.__version__) . Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)] pandas 1.1.3 . Para ilustrar, vamos a seleccionar los datos de la carpeta conjunto_de_datos_CB_ENSU_12_2020 (Cuestionario principal de la encuesta secci√≥n I, II, III y IV). . datos = pd.read_csv(&#39;conjunto_de_datos_CB_ENSU_12_2020/conjunto_de_datos/conjunto_de_datos_CB_ENSU_12_2020.csv&#39;) datos.head() . ID_VIV ID_PER UPM VIV_SEL R_SEL CVE_ENT NOM_ENT CVE_MUN NOM_MUN LOC ... BP4_1_5 BP4_1_6 BP4_1_7 BP4_1_8 BP4_1_9 FAC_SEL DOMINIO EST UPM_DIS EST_DIS . 0 100188.049 | 0100188.049.03 r | 100188 | 1 | 3 | 1 | Aguascalientes r | 1 | Aguascalientes r | 1 | ... | 2 | 2 | 2 | 2 | 2 | 4046 | U r | 3 | 10 | 1390 | . 1 100188.072 | 0100188.072.06 r | 100188 | 2 | 6 | 1 | Aguascalientes r | 1 | Aguascalientes r | 1 | ... | 2 | 2 | 2 | 2 | 2 | 6069 | U r | 3 | 10 | 1390 | . 2 100188.093 | 0100188.093.03 r | 100188 | 3 | 3 | 1 | Aguascalientes r | 1 | Aguascalientes r | 1 | ... | 2 | 2 | 2 | 2 | 2 | 3035 | U r | 3 | 10 | 1390 | . 3 100188.111 | 0100188.111.01 r | 100188 | 5 | 1 | 1 | Aguascalientes r | 1 | Aguascalientes r | 1 | ... | 2 | 2 | 2 | 2 | 2 | 3035 | U r | 3 | 10 | 1390 | . 4 100295.009 | 0100295.009.01 r | 100295 | 1 | 1 | 1 | Aguascalientes r | 1 | Aguascalientes r | 1 | ... | 2 | 2 | 2 | 2 | 2 | 1704 | U r | 4 | 20 | 1400 | . 5 rows √ó 176 columns . datos.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 22283 entries, 0 to 22282 Columns: 176 entries, ID_VIV to EST_DIS dtypes: float64(1), int64(84), object(91) memory usage: 29.9+ MB . Necesitamos el diccionario de variables y los cat√°logos. Para el diccionario de variables cargamos el archivo conjunto_de_datos_CB_ENSU_12_2020/diccionario_de_datos/diccionario_de_datos_CB_ENSU_12_2020.csv . preguntas = pd.read_csv(&#39;conjunto_de_datos_CB_ENSU_12_2020/diccionario_de_datos/diccionario_de_datos_CB_ENSU_12_2020.csv&#39;, encoding=&#39;latin1&#39;) preguntas.head(10) . NOMBRE_CAMPO NEMONICO TIPO LONGITUD RANGO_CLAVES . 0 Identificador de vivienda seleccionada | ID_VIV | Alfanum√©rico | 11 | 0100001.001,¬Ö,3299999.999 r | . 1 Identificador del informante seleccionado | ID_PER | Alfanum√©rico | 14 | 0100001.001.01,..., 3299999.999.30 r | . 2 Unidad Primaria de Muestreo | UPM | Num√©rico | 7 | 0100001¬Ö3299999 r | . 3 Vivienda seleccionada | VIV_SEL | Num√©rico | 2 | 01¬Ö09 r | . 4 N√∫mero de rengl√≥n de la persona seleccionada | R_SEL | Num√©rico | 2 | 01¬Ö30 r | . 5 Clave Entidad | CVE_ENT | Num√©rico | 2 | 01 r | . 6 Clave Entidad | CVE_ENT | Num√©rico | 2 | 02 r | . 7 Clave Entidad | CVE_ENT | Num√©rico | 2 | 03 r | . 8 Clave Entidad | CVE_ENT | Num√©rico | 2 | 04 r | . 9 Clave Entidad | CVE_ENT | Num√©rico | 2 | 05 r | . Este nos muestra c√≥mo aparece cada variable en el archivo de datos (&quot;NEMONICO&quot;) y cu√°l es su descripci√≥n (&quot;NOMBRE_CAMPO&quot;), adem√°s contiene el tipo y rango de valores que puede tener cada variable. Por esta raz√≥n, el nombre de cada variable puede estar repetido varias veces. Lo que haremos es eliminar los duplicados y quedarnos con los valores √∫nicos, para despu√©s crear un objeto diccionario que tenga como llaves el &quot;NEMONICO&quot; y como valores el &quot;NOMBRE_CAMPO&quot;. A continuaci√≥n se ve el proceso y el resultado: . dicc_preguntas = preguntas.drop_duplicates(subset=[&#39;NEMONICO&#39;]).set_index(&#39;NEMONICO&#39;)[&#39;NOMBRE_CAMPO&#39;].to_dict() print(str(dicc_preguntas)[:500]) . {&#39;ID_VIV&#39;: &#39;Identificador de vivienda seleccionada&#39;, &#39;ID_PER&#39;: &#39;Identificador del informante seleccionado&#39;, &#39;UPM&#39;: &#39;Unidad Primaria de Muestreo &#39;, &#39;VIV_SEL&#39;: &#39;Vivienda seleccionada&#39;, &#39;R_SEL&#39;: &#39;N√∫mero de rengl√≥n de la persona seleccionada&#39;, &#39;CVE_ENT&#39;: &#39;Clave Entidad&#39;, &#39;NOM_ENT&#39;: &#39;Nombre de la Entidad&#39;, &#39;CVE_MUN&#39;: &#39;Clave Municipio&#39;, &#39;NOM_MUN&#39;: &#39;Nombre del Municipio&#39;, &#39;LOC&#39;: &#39;Localidad&#39;, &#39;CD&#39;: &#39;Ciudad&#39;, &#39;NOM_CD&#39;: &#39;Nombre de la Ciudad&#39;, &#39;PER&#39;: &#39;Periodo de la entrevista&#39;, &#39;R_DEF&#39;: &#39;Resultado definiti . Para el cat√°logo tenemos que trabajar un poco m√°s porque la informaci√≥n est√° en muchos archivos. Primero vamos a generar una lista de todos los archivos en la carpeta catalogo. . dir_catalogos = &#39;conjunto_de_datos_CB_ENSU_12_2020/catalogos/&#39; archivos_catalogo_respuestas = glob.glob1(dir_catalogos, &#39;*.csv&#39;) archivos_catalogo_respuestas[:10] . [&#39;BP1_1.csv&#39;, &#39;BP1_10_1.csv&#39;, &#39;BP1_10_2.csv&#39;, &#39;BP1_10_3.csv&#39;, &#39;BP1_10_4.csv&#39;, &#39;BP1_10_5.csv&#39;, &#39;BP1_2_01.csv&#39;, &#39;BP1_2_02.csv&#39;, &#39;BP1_2_03.csv&#39;, &#39;BP1_2_04.csv&#39;] . A continuaci√≥n vamos a leer cada uno de los archivos individuales y generar un diccionario por comprensi√≥n que contenga como llaves el &quot;NEMONICO&quot; y los valores ser√°n otro diccionario que tiene la relaci√≥n de los valores num√©ricos y de texto para los valores de cada variable. . dicc_respuestas = { f[:-4]: pd.read_csv(f&#39;{dir_catalogos}/{f}&#39;, encoding=&#39;latin1&#39;, index_col=f[:-4])[&#39;descrip&#39;].to_dict() for f in archivos_catalogo_respuestas } print(str(dicc_respuestas)[:500]) . {&#39;BP1_1&#39;: {1: &#39;seguro?&#39;, 2: &#39;inseguro?&#39;, 9: &#39;No sabe / no responde&#39;}, &#39;BP1_10_1&#39;: {1: &#39;Mucha confianza&#39;, 2: &#39;Algo de confianza&#39;, 3: &#39;Algo de desconfianza&#39;, 4: &#39;Mucha desconfianza&#39;, 9: &#39;No sabe / no responde&#39;}, &#39;BP1_10_2&#39;: {1: &#39;Mucha confianza&#39;, 2: &#39;Algo de confianza&#39;, 3: &#39;Algo de desconfianza&#39;, 4: &#39;Mucha desconfianza&#39;, 9: &#39;No sabe / no responde&#39;}, &#39;BP1_10_3&#39;: {1: &#39;Mucha confianza&#39;, 2: &#39;Algo de confianza&#39;, 3: &#39;Algo de desconfianza&#39;, 4: &#39;Mucha desconfianza&#39;, 9: &#39;No sabe / no responde&#39;}, &#39;BP1_10_4&#39; . Ahora tenemos dos diccionarios, uno con las etiquetas de las variables (dicc_preguntas) y otro con las etiquetas de los valores de cada pregunta dicc_respuestas. En ambos diccionarios la llave principal es el n√©monico de la pregunta, por tanto si queremos saber cu√°les son las etiquetas de variables y valores solo tenemos que indexar los diccionarios con el nem√≥nico correspondiente, por ejemplo para &quot;SEX&quot; y &quot;BP1_1&quot; obtenemos: . print(&#39;Etiqueta de variable:&#39;, dicc_preguntas[&#39;SEX&#39;], &#39; nEtiqueta de valores&#39;,dicc_respuestas[&#39;SEX&#39;]) . Etiqueta de variable: Sexo Etiqueta de valores {1: &#39;Hombre&#39;, 2: &#39;Mujer&#39;} . print(&#39;Etiqueta de variable:&#39;, dicc_preguntas[&#39;BP1_1&#39;], &#39; nEtiqueta de valores&#39;,dicc_respuestas[&#39;BP1_1&#39;]) . Etiqueta de variable: Percepci√≥n de seguridad en la ciudad Etiqueta de valores {1: &#39;seguro?&#39;, 2: &#39;inseguro?&#39;, 9: &#39;No sabe / no responde&#39;} . Uso de las etiquetas . Ya que tenemos las etiquetas, veamos c√≥mo podemos usarlas para interpretar mejor en nuestros an√°lisis. Hagamos una tabulaci√≥n cruzada para ver la distribuci√≥n de respuestas de las variables &quot;SEX&quot; y &quot;BP1_1&quot; . Warning: En estos ejemplos no estamos considerando que cada observaci√≥n tiene una ponderaci√≥n distinta (variable FAC_SEL) por tanto los resultados no son estimaciones v√°lidas. En una pr√≥xima entrada veremos c√≥mo integrar las ponderaciones. . pd.crosstab(datos[&#39;SEX&#39;], datos[&#39;BP1_1&#39;]) . BP1_1 1 2 9 . SEX . 1 4268 | 5849 | 33 | . 2 3703 | 8379 | 51 | . El √≠ndice del dataframe y los nombres de las columnas contienen los valores num√©ricos de las categor√≠as. Vamos a reemplazarlos por sus valores de texto renombr√°ndolo con el m√©todo .rename() . pd.crosstab(datos[&#39;SEX&#39;], datos[&#39;BP1_1&#39;]) .rename(index=dicc_respuestas[&#39;SEX&#39;], columns=dicc_respuestas[&#39;BP1_1&#39;]) . BP1_1 seguro? inseguro? No sabe / no responde . SEX . Hombre 4268 | 5849 | 33 | . Mujer 3703 | 8379 | 51 | . Ahora es mucho m√°s f√°cil de entender esta tabla. . Vamos a hacer otra tabla similar a la anterior, pero en este caso desagregando por m√°s variables y usando el m√©todo groupby: . vars_by = [&#39;SEX&#39;, &#39;BP1_1&#39;, &#39;BP1_5_1&#39;] grouped = datos.groupby(vars_by).agg(N=(&#39;ID_PER&#39;, &#39;count&#39;)) grouped.head(15) . N . SEX BP1_1 BP1_5_1 . 1 1 1 1255 | . 2 2821 | . 3 190 | . 9 2 | . 2 1 3587 | . 2 2010 | . 3 249 | . 9 3 | . 9 1 14 | . 2 16 | . 3 3 | . 2 1 1 1463 | . 2 1995 | . 3 243 | . 9 2 | . Nuevamente reemplazamos los valores de las categor√≠as usando el m√©todo .rename(). Hacemos un loop para reemplazar las categor√≠as de cada variable. Como tenemos varios niveles en el √≠ndice, especificamos la opci√≥n level para que use solo el cat√°logo con la variable que le corresponde. . for v in vars_by: grouped.rename(index=dicc_respuestas[v], level=v, inplace=True) grouped . N . SEX BP1_1 BP1_5_1 . Hombre seguro? S√≠ 1255 | . No 2821 | . No aplica 190 | . No sabe / no responde 2 | . inseguro? S√≠ 3587 | . No 2010 | . No aplica 249 | . No sabe / no responde 3 | . No sabe / no responde S√≠ 14 | . No 16 | . No aplica 3 | . Mujer seguro? S√≠ 1463 | . No 1995 | . No aplica 243 | . No sabe / no responde 2 | . inseguro? S√≠ 5783 | . No 2192 | . No aplica 400 | . No sabe / no responde 4 | . No sabe / no responde S√≠ 19 | . No 23 | . No aplica 7 | . No sabe / no responde 2 | . Para que sea m√°s f√°cil de ver, reestructuramos la tabla usando .unstack(). . grouped.unstack(&#39;BP1_1&#39;) . N . BP1_1 No sabe / no responde inseguro? seguro? . SEX BP1_5_1 . Hombre No 16.0 | 2010.0 | 2821.0 | . No aplica 3.0 | 249.0 | 190.0 | . No sabe / no responde NaN | 3.0 | 2.0 | . S√≠ 14.0 | 3587.0 | 1255.0 | . Mujer No 23.0 | 2192.0 | 1995.0 | . No aplica 7.0 | 400.0 | 243.0 | . No sabe / no responde 2.0 | 4.0 | 2.0 | . S√≠ 19.0 | 5783.0 | 1463.0 | . Ya integramps las etiquetas de los valores, ahora faltan las etiquetas de las variables. Para eso usaremos el m√©todo .rename_axis() . cuadro = grouped.unstack(&#39;BP1_1&#39;) .rename_axis(index=dicc_preguntas, columns=dicc_preguntas) cuadro . N . Percepci√≥n de seguridad en la ciudad No sabe / no responde inseguro? seguro? . Sexo Cambiar sus h√°bitos respecto a llevar cosas de valor por temor a sufrir alg√∫n delito . Hombre No 16.0 | 2010.0 | 2821.0 | . No aplica 3.0 | 249.0 | 190.0 | . No sabe / no responde NaN | 3.0 | 2.0 | . S√≠ 14.0 | 3587.0 | 1255.0 | . Mujer No 23.0 | 2192.0 | 1995.0 | . No aplica 7.0 | 400.0 | 243.0 | . No sabe / no responde 2.0 | 4.0 | 2.0 | . S√≠ 19.0 | 5783.0 | 1463.0 | . Nuestro cuadro ya es entendible, podemos exportarlo a Excel y verificar que tenemos las etiquetas: . cuadro.to_excel(&#39;reporte.xlsx&#39;) . . Si usas Stata...(o incluso si no) . Como dije antes, el formato .dta permite guardar las etiquetas de variables y valores junto con los datos. Los DataFrames de Pandas traen de forma nativa el m√©todo .to_stata() para exportar la informaci√≥n a este formato. Para que Stata reconozca correctamnete las etiquetas de valores es necesario que en pandas las variables sean de tipo categoria. A continuaci√≥n, vamos a seleccionar un subconjunto de variables, reemplazaremos sus valores num√©ricos por las categor√≠as de texto y convertiremos la variable en tipo categ√≥rica: . vars_export = [&#39;SEX&#39;, &#39;BP1_1&#39;, &#39;BP1_2_01&#39;, &#39;BP1_2_02&#39;, &#39;BP1_2_03&#39;, &#39;BP1_2_04&#39;, &#39;BP1_2_05&#39;, &#39;BP1_2_06&#39;, &#39;BP1_2_07&#39;, &#39;BP1_2_08&#39;, &#39;BP1_2_09&#39;, &#39;BP1_2_10&#39;, &#39;BP1_2_11&#39;, &#39;BP1_2_12&#39;] datos_stata = datos[vars_export].apply(lambda s: s.map(dicc_respuestas[s.name])).astype(&#39;category&#39;) datos_stata . SEX BP1_1 BP1_2_01 BP1_2_02 BP1_2_03 BP1_2_04 BP1_2_05 BP1_2_06 BP1_2_07 BP1_2_08 BP1_2_09 BP1_2_10 BP1_2_11 BP1_2_12 . 0 Hombre | seguro? | Seguro(a) | No aplica | Seguro(a) | No aplica | No aplica | No aplica | No aplica | No aplica | No aplica | No aplica | No aplica | No aplica | . 1 Hombre | inseguro? | Seguro(a) | Inseguro(a) | Seguro(a) | No aplica | Seguro(a) | Seguro(a) | Inseguro(a) | Inseguro(a) | Inseguro(a) | Seguro(a) | Inseguro(a) | Seguro(a) | . 2 Hombre | inseguro? | Seguro(a) | Seguro(a) | Inseguro(a) | No aplica | No aplica | Seguro(a) | Inseguro(a) | Inseguro(a) | No aplica | Inseguro(a) | Inseguro(a) | Inseguro(a) | . 3 Mujer | inseguro? | Inseguro(a) | No aplica | Inseguro(a) | No aplica | Inseguro(a) | No aplica | No aplica | No aplica | No aplica | Inseguro(a) | No aplica | No aplica | . 4 Hombre | seguro? | Seguro(a) | Inseguro(a) | Seguro(a) | No aplica | No aplica | No aplica | Inseguro(a) | No aplica | No aplica | Inseguro(a) | Inseguro(a) | Inseguro(a) | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 22278 Hombre | inseguro? | Seguro(a) | Seguro(a) | Seguro(a) | No aplica | Inseguro(a) | Seguro(a) | Inseguro(a) | Inseguro(a) | Seguro(a) | Seguro(a) | Inseguro(a) | Seguro(a) | . 22279 Hombre | inseguro? | Seguro(a) | Seguro(a) | Inseguro(a) | No aplica | No aplica | Seguro(a) | Inseguro(a) | Inseguro(a) | No aplica | Seguro(a) | Seguro(a) | No aplica | . 22280 Hombre | seguro? | Seguro(a) | No aplica | Seguro(a) | No aplica | Seguro(a) | Seguro(a) | Seguro(a) | Seguro(a) | No aplica | Seguro(a) | Seguro(a) | No aplica | . 22281 Mujer | inseguro? | Seguro(a) | Inseguro(a) | Inseguro(a) | No aplica | Inseguro(a) | Inseguro(a) | Inseguro(a) | Inseguro(a) | No aplica | Inseguro(a) | Inseguro(a) | Inseguro(a) | . 22282 Mujer | seguro? | Seguro(a) | Seguro(a) | Inseguro(a) | No aplica | Inseguro(a) | Seguro(a) | Inseguro(a) | Seguro(a) | Seguro(a) | Seguro(a) | Seguro(a) | Inseguro(a) | . 22283 rows √ó 14 columns . Este dataframe lo exportaremos a Stata, junto con el diccionario que contiene las etiquetas de variables, especificando en la opci√≥n variable_labels. . datos_stata.to_stata(&#39;datos_stata.dta&#39;, write_index=False, variable_labels=dicc_preguntas) . Al abrir el arcivo en Stata podemos ver que efectivamente se guardaron las etiquetas de los valores y de las variables: . . Hasta donde entiendo, esta ser√≠a una forma m√°s f√°cil de etiquetar datos provenientes de INEGI para usuarios de Stata que haciendo el procedimiento entero en Stata. Igualmente, para los que no son usuarios de Stata, pero s√≠ de Python o R y quieren conservar las variables categ√≥ricas etiquetadas este es un buen formato. . datos_2 = pd.read_stata(&#39;datos_stata.dta&#39;) datos_2.dtypes . SEX category BP1_1 category BP1_2_01 category BP1_2_02 category BP1_2_03 category BP1_2_04 category BP1_2_05 category BP1_2_06 category BP1_2_07 category BP1_2_08 category BP1_2_09 category BP1_2_10 category BP1_2_11 category BP1_2_12 category dtype: object .",
            "url": "http://blog.jjsantoso.com/etiquetas-encuestas-inegi/",
            "relUrl": "/etiquetas-encuestas-inegi/",
            "date": " ‚Ä¢ Mar 8, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Generando archivos de Excel con formatos y gr√°ficas usando Python",
            "content": "Elaborado por Juan Javier Santos Ochoa (@jjsantoso) . Excel es un tipo de archivo muy com√∫n para compartir datos. No a todos les encanta, pero tiene la ventaja de que es muy popular y muchas personas no familiarizadas con la programaci√≥n lo usan para su an√°lisis. Una de las funciones de Excel que no es f√°cil de replicar con otras herramientas es la posibilidad de aplicar estilo a las celdas y generar tablas o reportes m√°s actractivos para presentar los datos. En esta entrada veremos c√≥mo, usando Python, podemos exportar datos a archivos de Excel aplicando estilos y formatos a las celdas. . Como ejemplo usaremos los datos de indicadores de desarrollo del Banco Mundial. En su p√°gina puedes ver y descargar mucha informaci√≥n. Ac√° puedes decargar los archivos que en particular uso en esta entrada. Desc√°rgalos y gu√°rdalos en una carpeta llamada datos. . Lo que haremos es crear fichas para los metadatos que sean m√°s f√°ciles de leer, ya que leer esta informaci√≥n tal como viene en el archivo original es un poco dif√≠cil. La idea es pasar de esto: . . a esto: . . Adem√°s, usaremos el formato condicional para establecer detalles como el color de las celdas dependiendo de sus valores. Luego, como bonus, aprovechando que ya sabremos usar xlsxwriter, veremos c√≥mo crear gr√°ficas que se guardan dentro del archivo de Excel. . Para seguir este tutorial es necesario tener instaladas las bibliotecas pandas y xlsxwriter. La biblioteca xlsxwriter es excelente y est√° muy bien documentada por su autor. La mayor parte de lo que aqu√≠ hacemos se basa en sus ejemplos. xlsxwriter se instala usando pip . pip install XlsxWriter . import xlsxwriter import pandas as pd print(xlsxwriter.__name__, xlsxwriter.__version__) print(pd.__name__, pd.__version__) . xlsxwriter 1.2.7 pandas 0.24.2 . Por brevedad solo leeremos las 10 primeras filas del archivo que contienen los metadatos. . metadata = pd.read_csv(&#39;datos/WDISeries.csv&#39;, nrows=10).fillna(&#39;&#39;) metadata.head() . Series Code Topic Indicator Name Short definition Long definition Unit of measure Periodicity Base Period Other notes Aggregation method ... Notes from original source General comments Source Statistical concept and methodology Development relevance Related source links Other web links Related indicators License Type Unnamed: 20 . 0 AG.AGR.TRAC.NO | Environment: Agricultural production | Agricultural machinery, tractors | | Agricultural machinery refers to the number of... | | Annual | | | Sum | ... | | | Food and Agriculture Organization, electronic ... | A tractor provides the power and traction to m... | Agricultural land covers more than one-third o... | | | | CC BY-4.0 | | . 1 AG.CON.FERT.PT.ZS | Environment: Agricultural production | Fertilizer consumption (% of fertilizer produc... | | Fertilizer consumption measures the quantity o... | | Annual | | | Weighted average | ... | | | Food and Agriculture Organization, electronic ... | Fertilizer consumption measures the quantity o... | Factors such as the green revolution, has led ... | | | | CC BY-4.0 | | . 2 AG.CON.FERT.ZS | Environment: Agricultural production | Fertilizer consumption (kilograms per hectare ... | | Fertilizer consumption measures the quantity o... | | Annual | | | Weighted average | ... | | | Food and Agriculture Organization, electronic ... | Fertilizer consumption measures the quantity o... | Factors such as the green revolution, has led ... | | | | CC BY-4.0 | | . 3 AG.LND.AGRI.K2 | Environment: Land use | Agricultural land (sq. km) | | Agricultural land refers to the share of land ... | | Annual | | | Sum | ... | | | Food and Agriculture Organization, electronic ... | Agricultural land constitutes only a part of a... | Agricultural land covers more than one-third o... | | | | CC BY-4.0 | | . 4 AG.LND.AGRI.ZS | Environment: Land use | Agricultural land (% of land area) | | Agricultural land refers to the share of land ... | | Annual | | | Weighted average | ... | | | Food and Agriculture Organization, electronic ... | Agriculture is still a major sector in many ec... | Agricultural land covers more than one-third o... | | | | CC BY-4.0 | | . 5 rows √ó 21 columns . Aplicar formato a las celdas . A continuaci√≥n vamos a crear un libro (workbook) con xlsxwriter llamado fichas_metadatos.xlsx. A este libro le agregamos una hoja (worksheet). . workbook = xlsxwriter.Workbook(f&#39;datos/fichas_metadatos.xlsx&#39;) worksheet = workbook.add_worksheet() . Empezaremos a configurar el tama√±o de las filas y columnas de la hoja. Esto lo hacemos con los m√©todos .set_column() y .set_row(). En .set_column() es importante especificar un rango, incluso si es una sola columna, de lo contrario obtendr√≠amos un error. Las unidades son las mismas que usa Excel para fijar el ancho y alto de las celdas. Cuando terminamos de editar cerramos el libro con workbook.close() y esto escribe el contenido al archivo. . worksheet.set_column(&#39;B:B&#39;, 25) worksheet.set_column(&#39;C:C&#39;, 20) worksheet.set_column(&#39;D:D&#39;, 25) worksheet.set_column(&#39;E:E&#39;, 50) # Cambiamos tama√±os de filas worksheet.set_row(0, 40) worksheet.set_row(1, 34) worksheet.set_row(2, 34) worksheet.set_row(3, 100) worksheet.set_row(4, 300) worksheet.set_row(5, 100) workbook.close() . As√≠ se ve el resultado hasta ahora: Las celdas no tienen contenido pero s√≠ tienen tama√±os diferentes. . Ahora vamos a combinar varias celdas y escribir algo de contenido. . with xlsxwriter.Workbook(f&#39;datos/fichas_metadatos.xlsx&#39;) as workbook: worksheet = workbook.add_worksheet() # Cambiamos tama√±os de columnas y filas worksheet.set_column(&#39;B:B&#39;, 25) worksheet.set_column(&#39;C:C&#39;, 30) worksheet.set_column(&#39;D:D&#39;, 25) worksheet.set_column(&#39;E:E&#39;, 50) worksheet.set_row(0, 40) worksheet.set_row(1, 34) worksheet.set_row(2, 34) worksheet.set_row(3, 100) worksheet.set_row(4, 100) # Escribimos t√≠tulo worksheet.merge_range(&#39;B1:E1&#39;, metadata.loc[0, &#39;Indicator Name&#39;]) # fila 2 worksheet.write(&#39;B2&#39;, &#39;C√≥digo de serie:&#39;) worksheet.write(&#39;C2&#39;, metadata.loc[0, &#39;Series Code&#39;]) worksheet.write(&#39;D2&#39;, &#39;T√≥pico:&#39;) worksheet.write(&#39;E2&#39;, metadata.loc[0, &#39;Topic&#39;]) . Con el m√©todo .merge_range() combinamos las celdas en el rango B1:E1 en una sola celda. Adem√°s, escribimos en esta misma celda el contenido del nombre del indicador (Indicator Name) del primer indicador que est√° en el DataFrame metadata. | Con el m√©todo .write() escribimos contenido espec√≠fico para cada una de las celdas en las siguientes filas. Por ejemplo, en la celda B2 escribimos el texto C√≥digo de serie: y en C2 escribimos el c√≥digo del indicador (Series Code) que viene en la primera fila del indicador. En las celdas D2 y E2 escribimos el t√≥pico del indicador. | Aqu√≠ tambi√©n cambiamos un poco la sintaxis para abrir el libro usando la expresion with ... as ...:. De esta forma todas las operaciones deben quedar bajo la indentaci√≥n y no hay necesidad de cerrar expl√≠citamente el libro. El resultado se ve as√≠: | . Ahora continuamos escribiendo otras variables en las filas. . with xlsxwriter.Workbook(f&#39;datos/fichas_metadatos.xlsx&#39;) as workbook: worksheet = workbook.add_worksheet() # Cambiamos tama√±os de columnas y filas worksheet.set_column(&#39;B:B&#39;, 25) worksheet.set_column(&#39;C:C&#39;, 30) worksheet.set_column(&#39;D:D&#39;, 25) worksheet.set_column(&#39;E:E&#39;, 50) worksheet.set_row(0, 40) worksheet.set_row(1, 34) worksheet.set_row(2, 34) worksheet.set_row(3, 100) worksheet.set_row(4, 100) # Escribimos t√≠tulo worksheet.merge_range(&#39;B1:E1&#39;, metadata.loc[0, &#39;Indicator Name&#39;]) # fila 2 worksheet.write(&#39;B2&#39;, &#39;C√≥digo de serie:&#39;) worksheet.write(&#39;C2&#39;, metadata.loc[0, &#39;Series Code&#39;]) worksheet.write(&#39;D2&#39;, &#39;T√≥pico:&#39;) worksheet.write(&#39;E2&#39;, metadata.loc[0, &#39;Topic&#39;]) # fila 3 worksheet.write(&#39;B3&#39;, &#39;Agregaci√≥n:&#39;) worksheet.write(&#39;C3&#39;, metadata.loc[0, &#39;Aggregation method&#39;]) worksheet.write(&#39;D3&#39;, &#39;Periodicidad:&#39;) worksheet.write(&#39;E3&#39;, metadata.loc[0, &#39;Periodicity&#39;]) # fila 4 worksheet.write(&#39;B4&#39;, &#39;Definici√≥n:&#39;) worksheet.merge_range(&#39;C4:E4&#39;, metadata.loc[0, &#39;Long definition&#39;]) # fila 5 worksheet.write(&#39;B5&#39;, &#39;Fuente:&#39;) worksheet.merge_range(&#39;C5:E5&#39;, metadata.loc[0, &#39;Source&#39;]) . . Ya que tenemos el contenido de las celdas, lo que nos falta es el aplicar formato para que se vea m√°s atractivo. . with xlsxwriter.Workbook(f&#39;datos/fichas_metadatos.xlsx&#39;) as workbook: worksheet = workbook.add_worksheet() # Cambiamos tama√±os de columnas y filas worksheet.set_column(&#39;B:B&#39;, 25) worksheet.set_column(&#39;C:C&#39;, 30) worksheet.set_column(&#39;D:D&#39;, 25) worksheet.set_column(&#39;E:E&#39;, 50) worksheet.set_row(0, 40) worksheet.set_row(1, 34) worksheet.set_row(2, 34) worksheet.set_row(3, 100) worksheet.set_row(4, 100) # Formato de titulo formato_titulo = workbook.add_format({ &#39;bold&#39;: 1, &#39;border&#39;: 1, &#39;align&#39;: &#39;center&#39;, &#39;valign&#39;: &#39;vcenter&#39;, &#39;fg_color&#39;: &#39;#333f4f&#39;, &#39;font_color&#39;: &#39;white&#39;, &#39;text_wrap&#39;: True}) # Formato de variables formato_variables = workbook.add_format({ &#39;bold&#39;: 1, &#39;border&#39;: 1, &#39;align&#39;: &#39;left&#39;, &#39;valign&#39;: &#39;top&#39;, &#39;fg_color&#39;: &#39;#ddebf7&#39;, &#39;font_color&#39;: &#39;black&#39;, &#39;text_wrap&#39;: True}) # Formato del texto normal formato_normal = workbook.add_format({ &#39;border&#39;: 1, &#39;align&#39;: &#39;left&#39;, &#39;valign&#39;: &#39;top&#39;, &#39;text_wrap&#39;: True}) # Escribimos t√≠tulo worksheet.merge_range(&#39;B1:E1&#39;, metadata.loc[0, &#39;Indicator Name&#39;], formato_titulo) # fila 2 worksheet.write(&#39;B2&#39;, &#39;C√≥digo de serie:&#39;, formato_variables) worksheet.write(&#39;C2&#39;, metadata.loc[0, &#39;Series Code&#39;], formato_normal) worksheet.write(&#39;D2&#39;, &#39;T√≥pico:&#39;, formato_variables) worksheet.write(&#39;E2&#39;, metadata.loc[0, &#39;Topic&#39;], formato_normal) # fila 3 worksheet.write(&#39;B3&#39;, &#39;Agregaci√≥n:&#39;, formato_variables) worksheet.write(&#39;C3&#39;, metadata.loc[0, &#39;Aggregation method&#39;], formato_normal) worksheet.write(&#39;D3&#39;, &#39;Periodicidad:&#39;, formato_variables) worksheet.write(&#39;E3&#39;, metadata.loc[0, &#39;Periodicity&#39;], formato_normal) # fila 4 worksheet.write(&#39;B4&#39;, &#39;Definici√≥n:&#39;, formato_variables) worksheet.merge_range(&#39;C4:E4&#39;, metadata.loc[0, &#39;Long definition&#39;], formato_normal) # fila 5 worksheet.write(&#39;B5&#39;, &#39;Fuente:&#39;, formato_variables) worksheet.merge_range(&#39;C5:E5&#39;, metadata.loc[0, &#39;Source&#39;], formato_normal) . Para ello debemos definir los formatos en el libro con el m√©todo workbook.add_format() al que le pasamos un diccionaro con las opciones de formato, como por ejemplo si queremos que el texto aparezca en negrita, que est√© alineado al centro, el color del texto y el del fondo de la celda. Todas las opciones disponibles y m√°s ejemplos se pueden encontrar en la documentaci√≥n de xlsxwriter. . Aqu√≠ definimos tres tipos de formato: el formato para el nombre del indicador (formato_titulo), el formato para las celdas que tienen el nombre de la variable (formato_variables) y el formato para escribir la informaci√≥n (formato_normal). Para aplicar el formato a una celda, o a un conjunto de ellas, debemos pasar el objeto formato como tercer input al m√©todo worksheet.write(). Y as√≠ luce el resultado final: . . Estas fichas son mucho m√°s f√°ciles de leer que en el formato original. . Para finalizar esta parte solo nos queda iterar sobre todo el dataframe y crear una ficha de metadato para cada indicador, cada una en una hoja diferente: . with xlsxwriter.Workbook(f&#39;datos/fichas_metadatos.xlsx&#39;) as workbook: for fila in metadata.index: # agrega nueva ahoja worksheet = workbook.add_worksheet() # nombre de la hoja worksheet.name = metadata.loc[fila, &#39;Series Code&#39;] # Cambiamos tama√±os de columnas y filas worksheet.set_column(&#39;B:B&#39;, 25) worksheet.set_column(&#39;C:C&#39;, 30) worksheet.set_column(&#39;D:D&#39;, 25) worksheet.set_column(&#39;E:E&#39;, 50) worksheet.set_row(0, 40) worksheet.set_row(1, 34) worksheet.set_row(2, 34) worksheet.set_row(3, 100) worksheet.set_row(4, 100) # Formato de titulo formato_titulo = workbook.add_format({ &#39;bold&#39;: 1, &#39;border&#39;: 1, &#39;align&#39;: &#39;center&#39;, &#39;valign&#39;: &#39;vcenter&#39;, &#39;fg_color&#39;: &#39;#333f4f&#39;, &#39;font_color&#39;: &#39;white&#39;, &#39;text_wrap&#39;: True}) # Formato de variables formato_variables = workbook.add_format({ &#39;bold&#39;: 1, &#39;border&#39;: 1, &#39;align&#39;: &#39;left&#39;, &#39;valign&#39;: &#39;top&#39;, &#39;fg_color&#39;: &#39;#ddebf7&#39;, &#39;font_color&#39;: &#39;black&#39;, &#39;text_wrap&#39;: True}) # Formato del texto normal formato_normal = workbook.add_format({ &#39;border&#39;: 1, &#39;align&#39;: &#39;left&#39;, &#39;valign&#39;: &#39;top&#39;, &#39;text_wrap&#39;: True}) # Escribimos t√≠tulo worksheet.merge_range(&#39;B1:E1&#39;, metadata.loc[fila, &#39;Indicator Name&#39;], formato_titulo) # fila 2 worksheet.write(&#39;B2&#39;, &#39;C√≥digo de serie:&#39;, formato_variables) worksheet.write(&#39;C2&#39;, metadata.loc[fila, &#39;Series Code&#39;], formato_normal) worksheet.write(&#39;D2&#39;, &#39;T√≥pico:&#39;, formato_variables) worksheet.write(&#39;E2&#39;, metadata.loc[fila, &#39;Topic&#39;], formato_normal) # fila 3 worksheet.write(&#39;B3&#39;, &#39;Agregaci√≥n:&#39;, formato_variables) worksheet.write(&#39;C3&#39;, metadata.loc[fila, &#39;Aggregation method&#39;], formato_normal) worksheet.write(&#39;D3&#39;, &#39;Periodicidad:&#39;, formato_variables) worksheet.write(&#39;E3&#39;, metadata.loc[fila, &#39;Periodicity&#39;], formato_normal) # fila 4 worksheet.write(&#39;B4&#39;, &#39;Definici√≥n:&#39;, formato_variables) worksheet.merge_range(&#39;C4:E4&#39;, metadata.loc[fila, &#39;Long definition&#39;], formato_normal) # fila 5 worksheet.write(&#39;B5&#39;, &#39;Fuente:&#39;, formato_variables) worksheet.merge_range(&#39;C5:E5&#39;, metadata.loc[fila, &#39;Source&#39;], formato_normal) . Formato condicional . xlsxwriter tambi√©n tiene la opci√≥n de aplicar formato condicional, esto es que el formato de la celda var√≠e dependiendo del valor de la celda. Esto es √∫til cuando reportamos datos y queremos, por ejemplo, que el color de la celda est√© relacionado con su valor, de forma que un valor m√°s alto da un color m√°s intenso. Esto se puede hacer directamente en Excel como menciona este tutorial. . Para ver c√≥mo funciona usaremos los datos de uno de los indicadores de desarrollo que vimos antes. El indicador es el de porcentaje de la tierra que es de uso agr√≠cola y se encuentra en el archivo indicador_tierra_agro.csv. El dataframe que creamos se llama datos. . datos = pd.read_csv(&#39;datos/indicador_tierra_agro.csv&#39;) .rename(columns=lambda x: str(x)) datos.head() . Country Name Country Code Indicator Name Indicator Code 1960 1961 1962 1963 1964 1965 ... 2011 2012 2013 2014 2015 2016 2017 2018 2019 Unnamed: 64 . 0 Arab World | ARB | Agricultural land (% of land area) | AG.LND.AGRI.ZS | NaN | 27.835643 | 27.826564 | 27.845522 | 27.847925 | 27.866972 | ... | 36.440808 | 36.472300 | 36.534503 | 36.607475 | 36.624759 | 36.610850 | NaN | NaN | NaN | NaN | . 1 Caribbean small states | CSS | Agricultural land (% of land area) | AG.LND.AGRI.ZS | NaN | 5.518775 | 5.526186 | 5.533597 | 5.538538 | 5.484190 | ... | 6.198839 | 6.186983 | 6.215388 | 6.226504 | 6.245770 | 6.268000 | NaN | NaN | NaN | NaN | . 2 Central Europe and the Baltics | CEB | Agricultural land (% of land area) | AG.LND.AGRI.ZS | NaN | 64.667028 | 64.625380 | 64.540412 | 64.591952 | 64.402941 | ... | 47.871658 | 47.515760 | 46.958264 | 46.895589 | 46.988619 | 46.715708 | NaN | NaN | NaN | NaN | . 3 Early-demographic dividend | EAR | Agricultural land (% of land area) | AG.LND.AGRI.ZS | NaN | 35.425733 | 35.400661 | 35.345373 | 35.313357 | 35.283656 | ... | 41.439188 | 41.511835 | 41.537124 | 41.476279 | 41.464427 | 41.466296 | NaN | NaN | NaN | NaN | . 4 East Asia &amp; Pacific | EAS | Agricultural land (% of land area) | AG.LND.AGRI.ZS | NaN | 43.329285 | 43.552552 | 43.807975 | 44.062835 | 44.395486 | ... | 48.795620 | 48.666721 | 48.340167 | 48.777005 | 47.678013 | 47.783780 | NaN | NaN | NaN | NaN | . 5 rows √ó 65 columns . Vamos a seleccionar solo el nombre del pa√≠s (o grupo de pa√≠ses) y un par de a√±os (2010 y 2016) de datos. Estos los vamos a guardar con formato condicional usando el siguiente c√≥digo: . with pd.ExcelWriter(&#39;datos/indicador_agro_formato.xlsx&#39;, engine=&#39;xlsxwriter&#39;) as excelfile: workbook = excelfile.book # Agregamos datos al libro sheetname = &#39;agro&#39; datos[[&#39;Country Name&#39;, &#39;2000&#39;, &#39;2016&#39;]].to_excel(excelfile, sheet_name=sheetname, index=False) # Definimos formatos formato_porcentaje = workbook.add_format({&#39;num_format&#39;: &#39;0.0 %&#39;, &#39;font_color&#39;: &#39;#FFFFFF&#39;}) formato_bg_blanco = workbook.add_format({&#39;bg_color&#39;: &#39;#FFFFFF&#39;}) formato_escala = {&#39;type&#39;: &#39;2_color_scale&#39;, &#39;min_color&#39;: &#39;#D9D9D9&#39;, &#39;max_color&#39;: &#39;#808080&#39;} worksheet = excelfile.sheets[sheetname] # Configuramos formato a los datos worksheet.set_column(&#39;A:A&#39;, 40, formato_bg_blanco) worksheet.set_column(&#39;B2:C265&#39;, 20, formato_porcentaje) worksheet.conditional_format(&#39;B2:C265&#39;, formato_escala) . Ac√° algunos detalles de lo que hace: . En esta ocasi√≥n usamos la funci√≥n pd.ExcelWriter para crear el archivo excelfile, que a su vez tiene un libro (workbook). Usamos el m√©todo .to_excel() para guardar los datos en excelfile. | Definimos varios formatos. El primero, formato_porcentaje, es para que los n√∫mero se vean con el s√≠mbolo de porcentaje; el segundo formato, formato_bg_blanco, es para que en la primera columna no se noten las divisiones de las celdas; y el tercero, formato_escala, es para hacer un formato de escala de 2 colores que va desde un color para el valor m√≠nimo hasta otro en el valor m√°ximo. Los valores intermedios reciben colores intermedios seg√∫n una escala de colores lineal. | Lo que sigue es aplicar estos formatos a los valores de la hoja donde hab√≠amos guardado los datos. El formato condicional se especifica con el m√©todo worksheet.conditional_format(). | . El resultado en Excel es el siguiente: . . Gr&#225;ficas en Excel . Por √∫ltimo, aprovechando que le entendemos un poco a xlsxwriter, podemos ver c√≥mo hacer gr√°ficas de Excel con los datos del libro. Puede parecer un poco extra√±o hacer gr√°ficas de Excel usando Python si podemos hacerlas directamente en Python usando una biblioteca como Matplotlib, sin embargo, una ventaja de Excel es que cualquiera puede editar luego las gr√°ficas, mientras que las creadas mediante Matplotlib no son directamente editables. . En este caso usamos los mismos datos anteriores del indicador de porcentaje de la tierra con uso agr√≠cola para hacer una gr√°fica de barras. . with pd.ExcelWriter(&#39;datos/grafica_indicador_agro.xlsx&#39;, engine=&#39;xlsxwriter&#39;) as excelfile: sheet_name = &#39;agro&#39; # Guarda los datos en el archivo datos[[&#39;Country Name&#39;, &#39;2000&#39;, &#39;2016&#39;]].to_excel(excelfile, sheet_name=sheet_name, index=False) # Obtiene el libro y hoja de trabajo workbook = excelfile.book worksheet = excelfile.sheets[sheet_name] # Crea un objeto tipo gr√°fica chart = workbook.add_chart({&#39;type&#39;: &#39;bar&#39;}) # Configura las series chart.add_series({ &#39;categories&#39;: f&#39;={sheet_name}!$A$2:$A$15&#39;, &#39;values&#39;: f&#39;={sheet_name}!$B$2:$B$15&#39;, &#39;name&#39;: f&#39;={sheet_name}!$B$1&#39;, &#39;gap&#39;: 8, }) chart.add_series({ &#39;categories&#39;: f&#39;={sheet_name}!$A$2:$A$15&#39;, &#39;values&#39;: f&#39;={sheet_name}!$C$2:$C$15&#39;, &#39;name&#39;: f&#39;={sheet_name}!$C$1&#39;, &#39;gap&#39;: 8, }) # configura opciones del gr√°fico chart.set_size({&#39;width&#39;: 650, &#39;height&#39;: 400}) chart.set_title({&#39;name&#39;: &#39;Porcentaje de tierra de uso agr√≠cola&#39;, &#39;name_font&#39;: {&#39;size&#39;: 12}}) chart.set_x_axis({&#39;name&#39;: &#39;Porcentaje&#39;, &#39;major_gridlines&#39;: {&#39;visible&#39;: True}}) # Introduce el grafico en la hoja worksheet.insert_chart(&#39;D2&#39;, chart) . Para agregar una gr√°fica creamos un objeto chart usando el m√©todo workbook.add_chart(), en este caso especificando que es de tipo barra. | Al objeto chart le pasamos 2 series, la del a√±o 2010 y la del 2016. Solo seleccionamos las primeras 15 observaciones para no sobrecargar la gr√°fica. Las categor√≠as son los nombres de los pa√≠ses, columna A, y las especificamos con la sintaxis de Excel para rangos de valores. Hacemos igual con los valores, que est√°n en las columnas B y C. Ponemos los nombres de las series y tambi√©n la opci√≥n gap, esta √∫ltima para controlar el ancho de las barras. | Configuramos el tama√±o de la gr√°fica, el t√≠tulo y la etiqueta en el eje x. | Finalmente introducimos la gr√°fica en la hoja de los datos, en la celda D2. | . El resultado luce as√≠ en Excel: . . Pueden encontrar m√°s ejemplos de gr√°ficas en la documentaci√≥n de xlsxwriter. . Con esto terminamos esta entrada cuyo objetivo principal fue introducir las funcionalidades que ofrece xlsxwriter para crear archivos de Excel con formatos mucho m√°s ricos. A m√≠ me ha servido mucho en mi trabajo, espero que a ti tambi√©n pueda resultarte √∫til. .",
            "url": "http://blog.jjsantoso.com/excel-formato-graficas/",
            "relUrl": "/excel-formato-graficas/",
            "date": " ‚Ä¢ Sep 18, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Trabajando con archivos de Excel complejos en Pandas",
            "content": "Elaborado por Juan Javier Santos Ochoa (@jjsantoso) . Pandas es la biblioteca por excelencia para trabajar con datos tabulares en Python. Muchos de estos datos, especialmente los que vienen de instituciones p√∫blicas, est√°n en formato de Excel, que en ocasiones pueden ser particularmente dif√≠ciles de leer por su estructura con celdas combinadas. En esta entrada veremos c√≥mo usar algunas de las opciones y trucos de Pandas para leer estos archivos complejos de forma efectiva. Es necesario tener instaladas las bibliotecas pandas y xlrd. . Como ejemplo usaremos los tabulados del mercado laboral que publica el INEGI para M√©xico. Estos datos se pueden descargar desde su p√°gina: https://www.inegi.org.mx/programas/enoe/15ymas/default.html#Tabulados . En particular, usaremos los tabulados del primer trimestre de 2020 para el estado de Aguascalientes. Ac√° puedes decargar el archivo que uso en este notebook y ac√° uno con todos los estados. . El archivo luce de la siguiente forma visto en Excel. . Encabezado: . . Final del archivo: . . Podemos ver que la estructura de los datos es bastante compleja. Algunos de los desaf√≠os de este archivo son: . El encabezado de la tabla de datos no empieza desde la primera fila, sino a partir de la fila 6 | El encabezado est√° conformado por 3 filas (la 6, 7 y 8) con diferentes niveles de informaci√≥n. Por ejemplo, el primer nivel contiene los valores &quot;Enero-Marzo 2020&quot;, &quot;Coeficientes de Variaci√≥n (%)&quot;, &quot;Errores Est√°ndar&quot; e &quot;Intervalos de Confianza al 90%&quot;. El segundo nivel solo contiene valores para las columnas que est√°n bajo &quot;Intervalos de Confianza al 90%&quot;. El tercer nivel es la desagregaci√≥n por sexo, junto con el total, excepto en la columna &quot;Intervalos de Confianza al 90%&quot;, donde representa los l√≠mites inferiores y superiores. | Hay hasta 4 niveles de desagregaci√≥n de los indicadores, que vienen especificados en las columnas A, B, C y D. Estos niveles expresan jerarqu√≠a entre las categor√≠as. Por ejemplo, la celda C14 hace referencia a la poblaci√≥n desocupada, que hace parte de la PEA (B12) y de la poblaci√≥n de 15 a√±os y m√°s (A11) | Despu√©s que la tabla de datos termina, hay un mont√≥n de notas al pie y comentarios en las celdas siguientes, que pueden ser entendidas como datos. | Las variables de las que nos interesa obtener informaci√≥n est√°n como filas, cuando quisi√©ramos que fueran columnas. | . Queda muy claro que estos datos distan mucho de tener una estructura Tidy. . En ocasiones ante una estructura tan compleja, lo m√°s f√°cil es hacer manualmente los cambios necesarios para que la tabla quede en un formato mucho m√°s entendible para nuestro programa que va a leer los datos. Esto es v√°lido cuando solo hay que modificar uno o pocos archivos, pero si se trata de un proceso que se tiene que aplicar para muchos archivos o se va a estar haciendo de manera recurrente tenemos que pensar en una forma de automatizar el preprocesamiento. . Afortunadamente Pandas cuenta con caracter√≠sticas que nos ayudan mucho con este tipo de archivos que tienen m√∫ltiples niveles en las filas y en las columnas. Esto coincide bastante bien con las caracter√≠sticas de Multindex y Multicolumn de los dataframes. . Empecemos importando los datos y viendo c√≥mo lucen si los cargamos tal cual como vienen. . import pandas as pd df = pd.read_excel(&#39;datos/2020_trim_1_Entidad_Aguascalientes.xls&#39;) df.head() . INEGI. Encuesta Nacional de Ocupaci√≥n y Empleo. Indicadores estrat√©gicos. Primer trimestre de 2020 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16 Unnamed: 17 Unnamed: 18 . 0 NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1 Indicadores Estrat√©gicos de Ocupaci√≥n y Empleo... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2 Entidad Federativa: | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 Aguascalientes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | INDICADOR | Enero - Marzo 2020 | NaN | NaN | Coeficientes de Variaci√≥n (%) | NaN | NaN | Errores Est√°ndar | NaN | NaN | Intervalos de Confianza al 90% | NaN | NaN | NaN | NaN | NaN | . Podemos hacer muy poco con esto, no hay nombres en las columnas y hay valores nulos por todos lados. Veamos la parte final del dataframe, donde tenemos todas las notas al pie, que realmente no es informaci√≥n que necesitamos para el an√°lisis. . df.tail(7) . INEGI. Encuesta Nacional de Ocupaci√≥n y Empleo. Indicadores estrat√©gicos. Primer trimestre de 2020 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16 Unnamed: 17 Unnamed: 18 . 296 14 | Se consideran &quot;personas con inter√©s para traba... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 297 NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 298 Las estimaciones que aparecen en este cuadro e... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 299 Nivel de precisi√≥n de las estimaciones: | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 300 Alta, CV en el rango de (0,15) | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 301 Moderada, CV en el rango de [15, 30) | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 302 Baja, CV de 30% en adelante | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . Para empezar a arreglar un poco las cosas, usemos las opci√≥n header que nos permite especificar cu√°les son las filas que son el encabezado de los datos. Si tuvieran un formato tidy entonces solo necesitar√≠amos una fila como header, pero en este caso tenemos 3 niveles para el header. Pandas nos permite especificar varios niveles si a la opci√≥n header le pasamos una lista con los n√∫mero de las filas (contando desde 0). . df = pd.read_excel(&#39;datos/2020_trim_1_Entidad_Aguascalientes.xls&#39;, header=[5, 6, 7]) df.head(3) . Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 INDICADOR Enero - Marzo 2020 Coeficientes de Variaci√≥n (%) Errores Est√°ndar Intervalos de Confianza al 90% . Unnamed: 0_level_1 Unnamed: 1_level_1 Unnamed: 2_level_1 Unnamed: 3_level_1 Unnamed: 4_level_1 Unnamed: 5_level_1 Unnamed: 6_level_1 Unnamed: 7_level_1 Unnamed: 8_level_1 Unnamed: 9_level_1 Unnamed: 10_level_1 Unnamed: 11_level_1 Unnamed: 12_level_1 Total Hombres Mujeres . Unnamed: 0_level_2 Unnamed: 1_level_2 Unnamed: 2_level_2 Unnamed: 3_level_2 Total Hombres Mujeres Total Hombres Mujeres Total Hombres Mujeres LIIC LSIC LIIC LSIC LIIC LSIC . 0 I. Poblaci√≥n total 1 | NaN | NaN | NaN | 1363581.0 | 661998.0 | 701583.0 | 1.423850 | 1.77911 | 1.43904 | 19415.0 | 11777 | 10096 | 1.33164e+06 | 1.39552e+06 | 642624 | 681372 | 684975 | 718191 | . 1 NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2 2. Poblaci√≥n de 15 a√±os y m√°s | NaN | NaN | NaN | 1014307.0 | 484719.0 | 529588.0 | 1.350378 | 1.6399 | 1.4333 | 13696.0 | 7948 | 7590 | 991775 | 1.03684e+06 | 471643 | 497795 | 517102 | 542074 | . El resultado que obtenemos es un dataframe con 3 niveles de columnas (Multicolumn). Ahora al menos los datos empiezan donde deber√≠an. Hagamos tambi√©n que la tabla termine donde debe terminar. Para eso usamos la opci√≥n skipfooter a la que le especificamos el n√∫mero de filas que debe ignorar partiendo desde la √∫ltima hacia arriba. En este caso son 16 filas con contenido que no nos interesa. . df = pd.read_excel(&#39;datos/2020_trim_1_Entidad_Aguascalientes.xls&#39;, header=[5, 6, 7], skipfooter=16) df.tail(3) . Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 INDICADOR Enero - Marzo 2020 Coeficientes de Variaci√≥n (%) Errores Est√°ndar Intervalos de Confianza al 90% . Unnamed: 0_level_1 Unnamed: 1_level_1 Unnamed: 2_level_1 Unnamed: 3_level_1 Unnamed: 4_level_1 Unnamed: 5_level_1 Unnamed: 6_level_1 Unnamed: 7_level_1 Unnamed: 8_level_1 Unnamed: 9_level_1 Unnamed: 10_level_1 Unnamed: 11_level_1 Unnamed: 12_level_1 Total Hombres Mujeres . Unnamed: 0_level_2 Unnamed: 1_level_2 Unnamed: 2_level_2 Unnamed: 3_level_2 Total Hombres Mujeres Total Hombres Mujeres Total Hombres Mujeres LIIC LSIC LIIC LSIC LIIC LSIC . 277 NaN | Tasas calculadas contra la poblaci√≥n ocupada n... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 278 NaN | NaN | Tasa de ocupaci√≥n en el sector informal 2 (TOSI2) | NaN | 20.1963 | 22.8466 | 16.3304 | 4.116332 | 4.48344 | 6.14149 | 0.831347 | 1.02432 | 1.00293 | 18.829 | 21.564 | 21.162 | 24.532 | 14.681 | 17.98 | . 279 NaN | NaN | Tasa de informalidad laboral 2 (TIL2) | NaN | 39.3077 | 37.4318 | 42.0439 | 2.655421 | 3.20142 | 3.24678 | 1.043784 | 1.19835 | 1.36507 | 37.591 | 41.025 | 35.461 | 39.403 | 39.798 | 44.289 | . Ahora el dataframe termina donde est√° el √∫ltimo indicador, que es &quot;Tasa de informalidad laboral 2 (TIL2)&quot;. . Ahora continuaremos con la opci√≥n index_col que le permite a Pandas entender que las primeras 4 columnas ser√°n el √≠ndice del dataframe. Lo mejor es que adem√°s entiende la estructura jer√°rquica que est√° impl√≠cita en las celdas combinadas. . df = pd.read_excel(&#39;datos/2020_trim_1_Entidad_Aguascalientes.xls&#39;, header=[5, 6, 7], skipfooter=16, index_col=[0, 1, 2, 3]) df.tail() . INDICADOR Enero - Marzo 2020 Coeficientes de Variaci√≥n (%) Errores Est√°ndar Intervalos de Confianza al 90% . Unnamed: 4_level_1 Unnamed: 5_level_1 Unnamed: 6_level_1 Unnamed: 7_level_1 Unnamed: 8_level_1 Unnamed: 9_level_1 Unnamed: 10_level_1 Unnamed: 11_level_1 Unnamed: 12_level_1 Total Hombres Mujeres . Total Hombres Mujeres Total Hombres Mujeres Total Hombres Mujeres LIIC LSIC LIIC LSIC LIIC LSIC . 10. Tasas Tasas calculadas contra la poblaci√≥n ocupada Tasa de ocupaci√≥n en el sector informal 1 (TOSI1) Mediana 19.4007 | 21.4890 | 16.1900 | 4.109763 | 4.49951 | 6.14659 | 0.797323 | 0.9669 | 0.995131 | 18.089 | 20.712 | 19.898 | 23.08 | 14.553 | 17.827 | . Tasa de informalidad laboral 1 (TIL1) Mediana 40.9383 | 40.0765 | 42.2632 | 2.532868 | 2.97923 | 3.20628 | 1.036912 | 1.19397 | 1.35508 | 39.233 | 42.644 | 38.112 | 42.041 | 40.034 | 44.492 | . Tasas calculadas contra la poblaci√≥n ocupada no agropecuaria Tasa de informalidad laboral 1 (TIL1) Mediana NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . Tasa de ocupaci√≥n en el sector informal 2 (TOSI2) Mediana 20.1963 | 22.8466 | 16.3304 | 4.116332 | 4.48344 | 6.14149 | 0.831347 | 1.02432 | 1.00293 | 18.829 | 21.564 | 21.162 | 24.532 | 14.681 | 17.98 | . Tasa de informalidad laboral 2 (TIL2) Mediana 39.3077 | 37.4318 | 42.0439 | 2.655421 | 3.20142 | 3.24678 | 1.043784 | 1.19835 | 1.36507 | 37.591 | 41.025 | 35.461 | 39.403 | 39.798 | 44.289 | . En este caso nos interesa obtener las estimaciones de los indicadores y no los coeficientes de variaci√≥n y los otros c√°lculos. Estos datos est√°n bajo la columna &quot;Enero - Marzo 2020&quot;, as√≠ que ya que tenemos encabezados es f√°cil obtenerlos. . df[&#39;Enero - Marzo 2020&#39;].head() . Unnamed: 4_level_1 Unnamed: 5_level_1 Unnamed: 6_level_1 . Total Hombres Mujeres . I. Poblaci√≥n total 1 NaN NaN NaN 1363581.0 | 661998.0 | 701583.0 | . NaN NaN | NaN | NaN | . 2. Poblaci√≥n de 15 a√±os y m√°s NaN NaN NaN 1014307.0 | 484719.0 | 529588.0 | . Poblaci√≥n econ√≥micamente activa (PEA) NaN NaN 603802.0 | 366686.0 | 237116.0 | . Ocupada NaN 583762.0 | 353706.0 | 230056.0 | . Queda sobrando un nivel que en realidad no necesitamos porque no agrega nada de informaci√≥n [&#39;Unnamed: 4_level_1&#39;, &#39;Unnamed: 5_level_1&#39;, &#39;Unnamed: 6_level_1&#39;]. Este lo podemos eliminar con el m√©todo .droplevel() . valores = df[&#39;Enero - Marzo 2020&#39;].droplevel(level=0, axis=1) valores.head() . Total Hombres Mujeres . I. Poblaci√≥n total 1 NaN NaN NaN 1363581.0 | 661998.0 | 701583.0 | . NaN NaN | NaN | NaN | . 2. Poblaci√≥n de 15 a√±os y m√°s NaN NaN NaN 1014307.0 | 484719.0 | 529588.0 | . Poblaci√≥n econ√≥micamente activa (PEA) NaN NaN 603802.0 | 366686.0 | 237116.0 | . Ocupada NaN 583762.0 | 353706.0 | 230056.0 | . Ya tenemos un resultado bastante √∫til. Todav√≠a nos quedan algunos ajustes que hacer. Primero, hay que eliminar las filas que solo contienen valores nulos . valores = valores.dropna(subset=[&#39;Total&#39;, &#39;Hombres&#39;, &#39;Mujeres&#39;]) valores.head() . Total Hombres Mujeres . I. Poblaci√≥n total 1 NaN NaN NaN 1363581.0 | 661998.0 | 701583.0 | . 2. Poblaci√≥n de 15 a√±os y m√°s NaN NaN NaN 1014307.0 | 484719.0 | 529588.0 | . Poblaci√≥n econ√≥micamente activa (PEA) NaN NaN 603802.0 | 366686.0 | 237116.0 | . Ocupada NaN 583762.0 | 353706.0 | 230056.0 | . Desocupada NaN 20040.0 | 12980.0 | 7060.0 | . Ahora pongamos nombres a los niveles para que sea f√°cil identificarlos. Tambi√©n cambiemos los NaN que hay en el √≠ndice por un valor de texto, como por ejemplo &quot;Total&quot;. Esto ayuda porque pandas no maneja muy bien valores nulos en el √≠ndice. . valores = valores.rename_axis(index=[&#39;nivel_1&#39;, &#39;nivel_2&#39;, &#39;nivel_3&#39;, &#39;nivel_4&#39;], columns=[&#39;sexo&#39;]) .rename(lambda x: &#39;Total&#39; if pd.isna(x) else x) valores.head() . sexo Total Hombres Mujeres . nivel_1 nivel_2 nivel_3 nivel_4 . I. Poblaci√≥n total 1 Total Total Total 1363581.0 | 661998.0 | 701583.0 | . 2. Poblaci√≥n de 15 a√±os y m√°s Total Total Total 1014307.0 | 484719.0 | 529588.0 | . Poblaci√≥n econ√≥micamente activa (PEA) Total Total 603802.0 | 366686.0 | 237116.0 | . Ocupada Total 583762.0 | 353706.0 | 230056.0 | . Desocupada Total 20040.0 | 12980.0 | 7060.0 | . Y bueno, ya con esto pr√°cticamente podemos obtener el valor de cualquiera de los indicadores. Por ejemplo, si queremos la &quot;Poblaci√≥n econ√≥micamente activa (PEA)&quot; . pea = valores.loc[(&#39;2. Poblaci√≥n de 15 a√±os y m√°s&#39;, &#39;Poblaci√≥n econ√≥micamente activa (PEA)&#39;)] pea . C: ProgramData Anaconda3 lib site-packages ipykernel_launcher.py:1: PerformanceWarning: indexing past lexsort depth may impact performance. &#34;&#34;&#34;Entry point for launching an IPython kernel. . sexo Total Hombres Mujeres . nivel_3 nivel_4 . Total Total 603802.0 | 366686.0 | 237116.0 | . Ocupada Total 583762.0 | 353706.0 | 230056.0 | . Desocupada Total 20040.0 | 12980.0 | 7060.0 | . En este resultado el nivel_4 es innecesario, as√≠ que lo podemos eliminar. En general, podemos eliminar cualquier nivel que no aporte informaci√≥n para quedarnos con una estructura m√°s sencilla. Adem√°s modificamos la estructura para que sea tidy y cada columna sea una variable . pea.droplevel(1) .T .add_prefix(&#39;poblacion_&#39;) .reset_index() . nivel_3 sexo poblacion_Total poblacion_Ocupada poblacion_Desocupada . 0 Total | 603802.0 | 583762.0 | 20040.0 | . 1 Hombres | 366686.0 | 353706.0 | 12980.0 | . 2 Mujeres | 237116.0 | 230056.0 | 7060.0 | . Podemos intentar con otro indicador como la Tasa de informalidad laboral 1 (TIL1), haciendo algunas otras modificaciones: . valores.loc[(&#39;10. Tasas&#39;, &#39;Tasas calculadas contra la poblaci√≥n ocupada&#39;, &#39;Tasa de informalidad laboral 1 (TIL1)&#39;)] .unstack(&#39;sexo&#39;) .to_frame(&#39;til_1&#39;) .droplevel(&#39;nivel_4&#39;) .reset_index() . C: ProgramData Anaconda3 lib site-packages ipykernel_launcher.py:1: PerformanceWarning: indexing past lexsort depth may impact performance. &#34;&#34;&#34;Entry point for launching an IPython kernel. . sexo til_1 . 0 Total | 40.9383 | . 1 Hombres | 40.0765 | . 2 Mujeres | 42.2632 | . Podemos convertir este procedimiento en una funci√≥n para que podamos obtener estas variables para cualquier estado. Por ejemplo, para obtener la poblaci√≥n econ√≥micamente activa creamos esta funci√≥n que depende solo del nombre del estado (como aparece en el archivo de INEGI que descargu√©) . def obtiene_pea(edo: str): df = pd.read_excel(f&#39;datos/2020_trim_1_Entidad_{edo}.xls&#39;, header=[5, 6, 7], skipfooter=16, index_col=[0, 1, 2, 3]) pea = df[&#39;Enero - Marzo 2020&#39;].droplevel(level=0, axis=1) .dropna(subset=[&#39;Total&#39;, &#39;Hombres&#39;, &#39;Mujeres&#39;]) .rename_axis(index=[&#39;nivel_1&#39;, &#39;nivel_2&#39;, &#39;nivel_3&#39;, &#39;nivel_4&#39;], columns=[&#39;sexo&#39;]) .rename(lambda x: &#39;Total&#39; if pd.isna(x) else x) .sort_index() .loc[(&#39;2. Poblaci√≥n de 15 a√±os y m√°s&#39;, &#39;Poblaci√≥n econ√≥micamente activa (PEA)&#39;)] .droplevel(1) .T .add_prefix(&#39;poblacion_&#39;) .reset_index() .assign(estado=edo.replace(&#39;_&#39;, &#39; &#39;)) return pea . Probamos la funci√≥n en otro estado y nos da el resultado esperado: . obtiene_pea(&#39;Oaxaca&#39;) . nivel_3 sexo poblacion_Desocupada poblacion_Ocupada poblacion_Total estado . 0 Total | 30743.0 | 1766690.0 | 1797433.0 | Oaxaca | . 1 Hombres | 18948.0 | 999821.0 | 1018769.0 | Oaxaca | . 2 Mujeres | 11795.0 | 766869.0 | 778664.0 | Oaxaca | . Ac√° por ejemplo, obtenemos la pea para los estados del Sur-Sureste mexicano: . pea_sur = pd.concat([obtiene_pea(e) for e in [&#39;Oaxaca&#39;, &#39;Chiapas&#39;, &#39;Tabasco&#39;, &#39;Campeche&#39;, &#39;Quintana_Roo&#39;, &#39;Yucat√°n&#39;]], ignore_index=True) pea_sur . nivel_3 sexo poblacion_Desocupada poblacion_Ocupada poblacion_Total estado . 0 Total | 30743.0 | 1766690.0 | 1797433.0 | Oaxaca | . 1 Hombres | 18948.0 | 999821.0 | 1018769.0 | Oaxaca | . 2 Mujeres | 11795.0 | 766869.0 | 778664.0 | Oaxaca | . 3 Total | 55562.0 | 2068483.0 | 2124045.0 | Chiapas | . 4 Hombres | 32413.0 | 1417037.0 | 1449450.0 | Chiapas | . 5 Mujeres | 23149.0 | 651446.0 | 674595.0 | Chiapas | . 6 Total | 57702.0 | 1031968.0 | 1089670.0 | Tabasco | . 7 Hombres | 31558.0 | 643777.0 | 675335.0 | Tabasco | . 8 Mujeres | 26144.0 | 388191.0 | 414335.0 | Tabasco | . 9 Total | 12364.0 | 435961.0 | 448325.0 | Campeche | . 10 Hombres | 7750.0 | 269822.0 | 277572.0 | Campeche | . 11 Mujeres | 4614.0 | 166139.0 | 170753.0 | Campeche | . 12 Total | 25607.0 | 851473.0 | 877080.0 | Quintana_Roo | . 13 Hombres | 14241.0 | 525859.0 | 540100.0 | Quintana_Roo | . 14 Mujeres | 11366.0 | 325614.0 | 336980.0 | Quintana_Roo | . 15 Total | 21992.0 | 1086089.0 | 1108081.0 | Yucat√°n | . 16 Hombres | 11421.0 | 651820.0 | 663241.0 | Yucat√°n | . 17 Mujeres | 10571.0 | 434269.0 | 444840.0 | Yucat√°n | . De esta manera logr√© obtener los indicadores que necesitaba de un archivo que parec√≠a imposible de aprovechar en su estado original. . Lo que m√°s quer√≠a destacar en esta entrada es que Pandas, con su estructura de multindex, puede facilitar mucho leer archivos de Excel cuya estructura incluye celdas combinadas y anidadas. No hay garant√≠a de que siempra se pueda leer adecuadamente archivos de Excel muy complejos, pero es bueno saber que tampoco est√° todo perdido si llega a tus manos uno de estos mosntruos. .",
            "url": "http://blog.jjsantoso.com/pandas-excel/",
            "relUrl": "/pandas-excel/",
            "date": " ‚Ä¢ Sep 9, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Redes y contratos p√∫blicos",
            "content": "Imports y globals . Imports . import pymongo import pandas as pd import json import matplotlib.pyplot as plt import networkx as nx from NetworkUtils import draw_network . globals . dir_datos = &#39;d:/datos/licitaciones_compranet&#39; myclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;) mydb = myclient[&#39;dataton2019&#39;] . Funciones . An&#225;lisis de asociados . Contacpoints . Creaci&#243;n de la base . Creamos una base de datos que tenga identificado a cada punto de contacto. | Los puntos de contacto se obtienen a partir de los contratistas que tienen informaci√≥n o su direcci√≥n. | . resultado = mydb.contrataciones.find({}, {&#39;_id&#39;: 0, &#39;parties.contactPoint&#39;: 1, &#39;parties.roles&#39;: 1, &#39;parties.id&#39;: 1, &#39;parties.address&#39;: 1}) . df_contactos = pd.DataFrame([{**p.get(&#39;contactPoint&#39;, &#39;&#39;), **p.get(&#39;address&#39;, &#39;&#39;), &#39;tenderer_id&#39;: p[&#39;id&#39;] } for x in resultado for p in x[&#39;parties&#39;] if (p[&#39;roles&#39;] in [[&#39;tenderer&#39;], [&#39;tenderer&#39;, &#39;supplier&#39;]]) &amp; ((bool(p.get(&#39;address&#39;, None))) | (bool(p.get(&#39;contactPoint&#39;, None))))]) df_contactos.to_pickle(f&#39;{dir_datos}/tenderers_contacpoint.pkl&#39;) df_contactos.head() . name email telephone streetAddress locality region postalCode countryName tenderer_id faxNumber . 0 IRAM LIEVANOS VELAZQUEZ | laroca.canino@gmail.com | 52 722 093749 | PASEO DE LA ASUNCION NO. 536 | METEPEC | MX-MEX | 52148 | M√âXICO | E9C1C827AE1234CCF7AC4D9070BB597C | NaN | . 1 NaN | servillantas@prodigy.net.mx | 10191684 | JOSE MORAN 66 | MIGUEL HIDALGO | MX-CMX | 11850 | M√âXICO | SCA031118BX7 | NaN | . 2 NaN | sportingautoreparaciones@gmail.com | 55 56397681 55 54894622 | PLUTARCO ELIAS CALLES No. 660. COL. SAN FRANCI... | Iztacalco | MX-CMX | 08230 | M√âXICO | SAU0505307M9 | NaN | . 3 EDGAR GUSTAVO TREJO KEMPER | edgarg_kemper@hotmail.com; balcazar-sol@hotmai... | 5543419836 | CALZADA VALLEJO NUMERO 1020 | AZCAPOTZALCO | MX-CMX | 02300 | M√âXICO | SCK070618C21 | 52 55 55873415 ext 201, 202, 203 | . 4 Daniel Ernesto De la Fuente Barra | daniel.delafuente@segurossura.com.mx | 5519636830 | BLVD ADOLFO LOPEZ MATEOS 2448 | ALVARO OBREGON | MX-CMX | 01060 | M√âXICO | R&amp;S811221KR6 | 57237999 Ext. 7965 | . De la base de datos de contrataciones seleccionamos los datos de contacto de los que han ganado licitaciones. Estos tiene datos como nombre de la persona de contacto, email, tel√©fono, n√∫mero de fax, direcci√≥n y id del proveedor | . Uso de la base . df_contactos = pd.read_pickle(f&#39;{dir_datos}/tenderers_contacpoint.pkl&#39;) df_contactos.head() . name email telephone streetAddress locality region postalCode countryName tenderer_id faxNumber . 0 IRAM LIEVANOS VELAZQUEZ | laroca.canino@gmail.com | 52 722 093749 | PASEO DE LA ASUNCION NO. 536 | METEPEC | MX-MEX | 52148 | M√âXICO | E9C1C827AE1234CCF7AC4D9070BB597C | NaN | . 1 NaN | servillantas@prodigy.net.mx | 10191684 | JOSE MORAN 66 | MIGUEL HIDALGO | MX-CMX | 11850 | M√âXICO | SCA031118BX7 | NaN | . 2 NaN | sportingautoreparaciones@gmail.com | 55 56397681 55 54894622 | PLUTARCO ELIAS CALLES No. 660. COL. SAN FRANCI... | Iztacalco | MX-CMX | 08230 | M√âXICO | SAU0505307M9 | NaN | . 3 EDGAR GUSTAVO TREJO KEMPER | edgarg_kemper@hotmail.com; balcazar-sol@hotmai... | 5543419836 | CALZADA VALLEJO NUMERO 1020 | AZCAPOTZALCO | MX-CMX | 02300 | M√âXICO | SCK070618C21 | 52 55 55873415 ext 201, 202, 203 | . 4 Daniel Ernesto De la Fuente Barra | daniel.delafuente@segurossura.com.mx | 5519636830 | BLVD ADOLFO LOPEZ MATEOS 2448 | ALVARO OBREGON | MX-CMX | 01060 | M√âXICO | R&amp;S811221KR6 | 57237999 Ext. 7965 | . df_contactos.shape . (563693, 10) . De todos los contratos encontramos 563693 puntos de contacto. Muchos de estos se repiten porque un contratista que gan√≥ varias veces aparecer√° como un contacto por cada contrato ganado. | Calculamos todas las combinaciones √∫nicas de telefono y tenderer_id. | Luego verificamos si existen casos en los que varios tenderer_id comparten el: tel√©fono: 700 casos en los que eso ocurre. | Email: 839 casos. | Nombre: 706 casos | N√∫mero de fax: 135 casos | Direcci√≥n de la calle: 172 casos | . | Todos estos son signos de sospecha. | En muchos casos hay cuentas de funcionarios p√∫blicos. Habr√≠a que verificar cu√°l es su papel. | La pregunta relevante es ¬øHay casos en los que contratistas que tienen contactos en com√∫n hayan participado en un mismo proceso de licitaci√≥n? | . variables_contacto = [&#39;telephone&#39;, &#39;email&#39;, &#39;name&#39;, &#39;streetAddress&#39;, &#39;faxNumber&#39;] casos = [] for var_duplicated in variables_contacto: # Encontramos todos los valores √∫nicos de la variable de contacto y de tenderer_id dups_direccion = df_contactos.loc[lambda x: (~x.duplicated(subset=[&#39;tenderer_id&#39;, var_duplicated])) &amp; (x[var_duplicated].notnull())] .loc[lambda x: (x[var_duplicated].duplicated()) &amp; (~x[&#39;name&#39;].str[:22].eq(&#39;- (Cuenta administrada&#39;)), var_duplicated].unique() # Encontramos cu√°les son los tenderers_id que comparten un mismo contacto tenderers_dup_id = [df_contactos.loc[lambda x: x[var_duplicated].eq(dup)].drop_duplicates(subset=[&#39;tenderer_id&#39;])[&#39;tenderer_id&#39;].tolist() for dup in dups_direccion] # Buscamos los contratos en los que participaron los ids asociados queries_dup = [[{&#39;parties.id&#39;: i} for i in x] for x in tenderers_dup_id] for q in queries_dup: resultado = list(mydb.contrataciones.find({&#39;$and&#39;: q}, {&#39;_id&#39;: 0, &#39;ocid&#39;: 1})) if resultado: tenderers_id = [x[&#39;parties.id&#39;] for x in q] ocids = list({x[&#39;ocid&#39;] for x in resultado}) casos.append({&#39;tenderer_ids&#39;: tenderers_id, &#39;contratos_ocid&#39;: ocids, &#39;variable&#39;: var_duplicated}) print(q) with open(&#39;datos/casos_colusion.json&#39;, &#39;w&#39;, encoding=&#39;utf8&#39;) as jsonfile: json.dump(casos, jsonfile) . El resultado que encontramos es que existen 571 casos de contratistas posiblemente relacionados en una misma licitaci√≥n. | . with open(&#39;datos/casos_colusion.json&#39;, &#39;r&#39;, encoding=&#39;utf8&#39;) as jsonfile: casos = json.load(jsonfile) . casos_ocid = list({c for cas in casos for c in cas[&#39;contratos_ocid&#39;]}) len(casos_ocid) . 571 . casos_contratos = list(mydb.contrataciones.find({&#39;ocid&#39;: {&#39;$in&#39;: casos_ocid}})) len(casos_contratos) . 619 . datos_contrato = [{&#39;titulo&#39;: c[&#39;contracts&#39;][0][&#39;title&#39;], &#39;descr&#39;: c[&#39;contracts&#39;][0].get(&#39;description&#39;, &#39;&#39;), &#39;valor&#39;: c[&#39;contracts&#39;][0][&#39;value&#39;][&#39;amount&#39;], &#39;dependencia_id&#39;: c[&#39;buyer&#39;][&#39;id&#39;], &#39;dependencia_nombre&#39;: c[&#39;buyer&#39;][&#39;name&#39;], &#39;uc_id&#39;: c[&#39;tender&#39;][&#39;procuringEntity&#39;][&#39;id&#39;], &#39;uc_name&#39;: c[&#39;tender&#39;][&#39;procuringEntity&#39;][&#39;name&#39;], &#39;ocid&#39;: c[&#39;ocid&#39;], &#39;fecha&#39;: c[&#39;date&#39;], } for c in casos_contratos if c.get(&#39;contracts&#39;, None)] df_datos_contratos = pd.DataFrame(datos_contrato).set_index(&#39;ocid&#39;) df_datos_contratos.head() . titulo descr valor dependencia_id dependencia_nombre uc_id uc_name fecha . ocid . ocds-07smqs-1317308 Servicio Integral de Suministro, Mantenimiento... | Servicio Integral de Suministro, Mantenimiento... | 450000.00 | CNBV-80 | Comisi√≥n Nacional Bancaria y de Valores | CNB950501PT6-006B00001 | CNBV-Direcci√≥n General Adjunta de Adquisicione... | 2017-03-29T05:13:19Z | . ocds-07smqs-1367848 PRESTADOR DE SERVICIOS INTEGRALES | PRESTADOR DE SERVICIOS INTEGRALES (HONORARIOS) | 44542.62 | SAGARPA-261 | Secretar√≠a de Agricultura, Ganader√≠a, Desarrol... | SAG010710V98-008000995 | SAGARPA-Delegacion Chihuahua #008000995 | 2017-05-22T12:24:14Z | . ocds-07smqs-1430619 CONTRATACI√ìN ABIERTA DEL SERVICIO DE LECTURA E... | CONTRATACI√ìN ABIERTA DEL SERVICIO DE LECTURA E... | 220000.00 | SEP-265 | Secretar√≠a de Educaci√≥n P√∫blica | SEP210905778-011000999 | SEP-Direcci√≥n de Adquisiciones #011000999 | 2017-07-20T06:22:43Z | . ocds-07smqs-1444924 SERVICIO DE MANTENIMIENTO CORRECTIVO AL SISTEM... | SERVICIO DE MANTENIMIENTO CORRECTIVO AL SISTEM... | 287780.00 | CONAGUA-94 | Comisi√≥n Nacional del Agua | CNA890116SF2-016B00009 | CONAGUA-Gerencia de Resursos Materiales #016B0... | 2017-08-03T01:58:53Z | . ocds-07smqs-1452158 SERVICIO DE DIFUSI√ìN EN MEDIOS DIGITALES DE LA... | SERVICIO DE DIFUSI√ìN EN MEDIOS DIGITALES DE LA... | 68950.00 | CONUEE-98 | Comisi√≥n Nacional para el Uso Eficiente de la ... | CNU800928K31-018E00999 | CONUEE-Direcci√≥n de Recursos Materiales y Serv... | 2017-08-30T04:21:41Z | . casos_contratos[0] . {&#39;_id&#39;: ObjectId(&#39;5dcdb0c10d84ead5c49d2e99&#39;), &#39;publisher&#39;: {&#39;uid&#39;: &#39;27511&#39;, &#39;name&#39;: &#39;SECRETAR√çA DE LA FUNCI√ìN P√öBLICA&#39;, &#39;uri&#39;: &#39;http://www.gob.mx/sfp&#39;}, &#39;cycle&#39;: 2017, &#39;ocid&#39;: &#39;ocds-07smqs-1317308&#39;, &#39;id&#39;: &#39;SFP-1317308-2018-11-12&#39;, &#39;date&#39;: &#39;2017-03-29T05:13:19Z&#39;, &#39;tag&#39;: [&#39;tender&#39;, &#39;award&#39;], &#39;initiationType&#39;: &#39;tender&#39;, &#39;parties&#39;: [{&#39;name&#39;: &#39;Comisi√≥n Nacional Bancaria y de Valores&#39;, &#39;id&#39;: &#39;CNBV-80&#39;, &#39;roles&#39;: [&#39;buyer&#39;]}, {&#39;name&#39;: &#39;CNBV-Direcci√≥n General Adjunta de Adquisiciones y Contratos #006B00001&#39;, &#39;id&#39;: &#39;CNB950501PT6-006B00001&#39;, &#39;identifier&#39;: {&#39;id&#39;: &#39;CNB950501PT6-006B00001&#39;, &#39;legalName&#39;: &#39;CNBV-Direcci√≥n General Adjunta de Adquisiciones y Contratos #006B00001&#39;, &#39;scheme&#39;: &#39;MX-RFC&#39;, &#39;uri&#39;: &#39;https://portalsat.plataforma.sat.gob.mx/ConsultaRFC&#39;}, &#39;address&#39;: {&#39;streetAddress&#39;: &#39;Av. Insurgentes Sur No. 1971, Torre Sur, Piso 6, Col. Guadalupe Inn&#39;, &#39;locality&#39;: &#39;√Ålvaro Obreg√≥n&#39;, &#39;region&#39;: &#39;Ciudad de M√©xico&#39;, &#39;postalCode&#39;: &#39;01020&#39;, &#39;countryName&#39;: &#39;MX&#39;}, &#39;contactPoint&#39;: {&#39;name&#39;: &#39;Jannet Miriam Mart√≠nez S√°nchez&#39;, &#39;email&#39;: &#39;jmartinezs@cnbv.gob.mx&#39;, &#39;telephone&#39;: &#39;1454-6537 y 1454-6538&#39;}, &#39;roles&#39;: [&#39;procuringEntity&#39;]}, {&#39;name&#39;: &#39;MARIANA REGALADO SOBERON&#39;, &#39;id&#39;: &#39;3CAB041C0551441CB0A31EAC594B2339&#39;, &#39;identifier&#39;: {&#39;id&#39;: &#39;3CAB041C0551441CB0A31EAC594B2339&#39;, &#39;legalName&#39;: &#39;MARIANA REGALADO SOBERON&#39;, &#39;scheme&#39;: &#39;MX-RFC&#39;, &#39;uri&#39;: &#39;https://portalsat.plataforma.sat.gob.mx/ConsultaRFC&#39;}, &#39;address&#39;: {}, &#39;contactPoint&#39;: {}, &#39;roles&#39;: [&#39;tenderer&#39;]}, {&#39;name&#39;: &#39;GRUPO SANMARI SA DE CV&#39;, &#39;id&#39;: &#39;GSA0310175N4&#39;, &#39;identifier&#39;: {&#39;id&#39;: &#39;GSA0310175N4&#39;, &#39;legalName&#39;: &#39;GRUPO SANMARI SA DE CV&#39;, &#39;scheme&#39;: &#39;MX-RFC&#39;, &#39;uri&#39;: &#39;https://portalsat.plataforma.sat.gob.mx/ConsultaRFC&#39;}, &#39;address&#39;: {&#39;streetAddress&#39;: &#39;AZTECAS 81 LA ROMANA&#39;, &#39;locality&#39;: &#39;Tlalnepantla de Baz&#39;, &#39;region&#39;: &#39;MX-MEX&#39;, &#39;postalCode&#39;: &#39;54050&#39;, &#39;countryName&#39;: &#39;M√âXICO&#39;}, &#39;contactPoint&#39;: {&#39;email&#39;: &#39;rafael@sanmari.com.mx&#39;, &#39;telephone&#39;: &#39;55-52409421&#39;}, &#39;roles&#39;: [&#39;tenderer&#39;]}, {&#39;name&#39;: &#39;HECTOR MANUEL SEGURA TORRE&#39;, &#39;id&#39;: &#39;E2E9D6DA235621FC08C1A0EFC4201B95&#39;, &#39;identifier&#39;: {&#39;id&#39;: &#39;E2E9D6DA235621FC08C1A0EFC4201B95&#39;, &#39;legalName&#39;: &#39;HECTOR MANUEL SEGURA TORRE&#39;, &#39;scheme&#39;: &#39;MX-RFC&#39;, &#39;uri&#39;: &#39;https://portalsat.plataforma.sat.gob.mx/ConsultaRFC&#39;}, &#39;address&#39;: {}, &#39;contactPoint&#39;: {}, &#39;roles&#39;: [&#39;tenderer&#39;]}, {&#39;name&#39;: &#39;GABRIEL DEL POZO RUIZ&#39;, &#39;id&#39;: &#39;AA2EEEF597460501F7B8A50B4DE1F671&#39;, &#39;identifier&#39;: {&#39;id&#39;: &#39;AA2EEEF597460501F7B8A50B4DE1F671&#39;, &#39;legalName&#39;: &#39;GABRIEL DEL POZO RUIZ&#39;, &#39;scheme&#39;: &#39;MX-RFC&#39;, &#39;uri&#39;: &#39;https://portalsat.plataforma.sat.gob.mx/ConsultaRFC&#39;}, &#39;address&#39;: {&#39;streetAddress&#39;: &#39;CEIBAS 45&#39;, &#39;locality&#39;: &#39;NAUCALPAN DE JUAREZ&#39;, &#39;region&#39;: &#39;MX-MEX&#39;, &#39;postalCode&#39;: &#39;53240&#39;, &#39;countryName&#39;: &#39;M√âXICO&#39;}, &#39;contactPoint&#39;: {&#39;name&#39;: &#39;GABRIEL DEL POZO RUIZ&#39;, &#39;email&#39;: &#39;mascontrolmenoscosto@yahoo.com.mx&#39;, &#39;telephone&#39;: &#39;525536259819&#39;}, &#39;roles&#39;: [&#39;tenderer&#39;, &#39;supplier&#39;]}], &#39;buyer&#39;: {&#39;name&#39;: &#39;Comisi√≥n Nacional Bancaria y de Valores&#39;, &#39;id&#39;: &#39;CNBV-80&#39;}, &#39;tender&#39;: {&#39;id&#39;: &#39;1317308&#39;, &#39;title&#39;: &#39;Servicio Integral de Suministro, Mantenimiento Plantas y Macetas&#39;, &#39;description&#39;: &#39;Servicio Integral de Suministro, Mantenimiento y Conservaci√≥n de Plantas Naturales y Macetas Propiedad de la CNBV&#39;, &#39;status&#39;: &#39;complete&#39;, &#39;procuringEntity&#39;: {&#39;name&#39;: &#39;CNBV-Direcci√≥n General Adjunta de Adquisiciones y Contratos #006B00001&#39;, &#39;id&#39;: &#39;CNB950501PT6-006B00001&#39;}, &#39;items&#39;: [{&#39;id&#39;: &#39;7044016&#39;, &#39;description&#39;: &#39;Contrataci√≥n de una P√≥liza de Seguro de Accidentes Personales para la protecci√≥n de los participantes en acciones de capacitaci√≥n del Programa de Apoyo al Empleo 2016.&#39;, &#39;classification&#39;: {&#39;id&#39;: &#39;33900006&#39;, &#39;description&#39;: &#39;Servicios de seguros de gastos medicos mayores&#39;}, &#39;quantity&#39;: 1, &#39;unit&#39;: {&#39;name&#39;: &#39;Servicio&#39;}}], &#39;value&#39;: {&#39;amount&#39;: 0}, &#39;procurementMethod&#39;: &#39;direct&#39;, &#39;procurementMethodRationale&#39;: &#39;Art. 42 p√°rrafo primero&#39;, &#39;submissionMethod&#39;: [&#39;electronicSubmission&#39;], &#39;tenderPeriod&#39;: {&#39;startDate&#39;: &#39;2017-03-29T05:13:19Z&#39;}, &#39;enquiryPeriod&#39;: {&#39;startDate&#39;: &#39;2017-03-29T05:13:19Z&#39;}, &#39;hasEnquiries&#39;: False, &#39;awardPeriod&#39;: {&#39;endDate&#39;: &#39;2017-03-30T00:00:00Z&#39;}, &#39;numberOfTenderers&#39;: 4, &#39;tenderers&#39;: [{&#39;name&#39;: &#39;MARIANA REGALADO SOBERON&#39;, &#39;id&#39;: &#39;3CAB041C0551441CB0A31EAC594B2339&#39;}, {&#39;name&#39;: &#39;GRUPO SANMARI SA DE CV&#39;, &#39;id&#39;: &#39;GSA0310175N4&#39;}, {&#39;name&#39;: &#39;GABRIEL DEL POZO RUIZ&#39;, &#39;id&#39;: &#39;AA2EEEF597460501F7B8A50B4DE1F671&#39;}, {&#39;name&#39;: &#39;HECTOR MANUEL SEGURA TORRE&#39;, &#39;id&#39;: &#39;E2E9D6DA235621FC08C1A0EFC4201B95&#39;}]}, &#39;language&#39;: &#39;es&#39;, &#39;awards&#39;: [{&#39;id&#39;: &#39;1399908&#39;, &#39;title&#39;: &#39;Servicio Integral de Suministro, Mantenimiento Plantas y Macetas&#39;, &#39;description&#39;: &#39;Servicio Integral de Suministro, Mantenimiento y Conservaci√≥n de Plantas Naturales y Macetas Propiedad de la CNBV&#39;, &#39;status&#39;: &#39;active&#39;, &#39;value&#39;: {&#39;amount&#39;: 450000, &#39;currency&#39;: &#39;MXN&#39;}, &#39;suppliers&#39;: [{&#39;name&#39;: &#39;GABRIEL DEL POZO RUIZ&#39;, &#39;id&#39;: &#39;AA2EEEF597460501F7B8A50B4DE1F671&#39;}], &#39;items&#39;: [{&#39;id&#39;: &#39;4645830&#39;, &#39;description&#39;: &#39;Servicio Integral de Suministro, Mantenimiento Plantas y Macetas&#39;, &#39;classification&#39;: {&#39;scheme&#39;: &#39;CUCOP: Clasificador √önico de las Contrataciones P√∫blicas&#39;, &#39;id&#39;: &#39;35900004&#39;, &#39;description&#39;: &#39;Servicios de jardineria&#39;, &#39;uri&#39;: &#39;https://compranetinfo.funcionpublica.gob.mx/descargas/CUCOP.xlsx&#39;}, &#39;quantity&#39;: 1, &#39;unit&#39;: {&#39;name&#39;: &#39;Servicio&#39;, &#39;value&#39;: {&#39;amount&#39;: 450000, &#39;currency&#39;: &#39;MXN&#39;}}}], &#39;contractPeriod&#39;: {&#39;startDate&#39;: &#39;2017-04-14T09:00:00Z&#39;, &#39;endDate&#39;: &#39;2018-06-18T03:59:00Z&#39;}}], &#39;contracts&#39;: [{&#39;id&#39;: 1399908, &#39;awardID&#39;: &#39;1399908&#39;, &#39;title&#39;: &#39;Servicio Integral de Suministro, Mantenimiento Plantas y Macetas&#39;, &#39;description&#39;: &#39;Servicio Integral de Suministro, Mantenimiento y Conservaci√≥n de Plantas Naturales y Macetas Propiedad de la CNBV&#39;, &#39;status&#39;: &#39;terminated&#39;, &#39;period&#39;: {&#39;startDate&#39;: &#39;2017-04-14T09:00:00Z&#39;, &#39;endDate&#39;: &#39;2018-06-18T03:59:00Z&#39;}, &#39;value&#39;: {&#39;amount&#39;: 450000, &#39;currency&#39;: &#39;MXN&#39;}, &#39;items&#39;: [{&#39;id&#39;: &#39;4645830&#39;, &#39;description&#39;: &#39;Servicio Integral de Suministro, Mantenimiento Plantas y Macetas&#39;, &#39;classification&#39;: {&#39;id&#39;: &#39;35900004&#39;, &#39;description&#39;: &#39;Servicios de jardineria&#39;}, &#39;quantity&#39;: 1, &#39;unit&#39;: {&#39;name&#39;: &#39;Servicio&#39;, &#39;value&#39;: {&#39;amount&#39;: 450000, &#39;currency&#39;: &#39;MXN&#39;}}}]}]} . participantes_contrato = {c[&#39;ocid&#39;]: [p[&#39;id&#39;] for p in c[&#39;parties&#39;] if p[&#39;roles&#39;] in [[&#39;tenderer&#39;], [&#39;tenderer&#39;, &#39;supplier&#39;]]] for c in casos_contratos} # N√∫mero de particpantes que estaban asociados en cada contrato asociados_contrato = {o: c[&#39;tenderer_ids&#39;] for c in casos for o in c[&#39;contratos_ocid&#39;]} # ganador contrato ganadores_contrato = {c[&#39;ocid&#39;]: [p[&#39;id&#39;] for p in c[&#39;parties&#39;] if p[&#39;roles&#39;]==[&#39;tenderer&#39;, &#39;supplier&#39;]] for c in casos_contratos} # dataframe df_asoc = pd.DataFrame([participantes_contrato, asociados_contrato, ganadores_contrato]).T .rename(columns={0: &#39;part&#39;, 1: &#39;asoc&#39;, 2: &#39;gana&#39;}) .assign(N_part=lambda x: x[&#39;part&#39;].str.len(), N_asoc=lambda x: x[&#39;asoc&#39;].str.len(), N_gana=lambda x: x[&#39;gana&#39;].str.len(), prop_asoc_part=lambda x: x[&#39;N_asoc&#39;].div(x[&#39;N_part&#39;]), part_mayo=lambda x: x[&#39;prop_asoc_part&#39;].ge(0.5), asoc_ganadores=lambda x: x.apply(lambda y: list(set(y[&#39;gana&#39;]).intersection(set(y[&#39;asoc&#39;]))), axis=1), N_asoc_ganadores=lambda x: x[&#39;asoc_ganadores&#39;].str.len(), part_nogana=lambda x: x.apply(lambda y: list(set(y[&#39;part&#39;]).difference(set(y[&#39;gana&#39;]))), axis=1)) .join(df_datos_contratos) df_asoc.to_pickle(f&#39;{dir_datos}/df_asociados.pkl&#39;) df_asoc.head() . part asoc gana N_part N_asoc N_gana prop_asoc_part part_mayo asoc_ganadores N_asoc_ganadores part_nogana titulo descr valor dependencia_id dependencia_nombre uc_id uc_name fecha . ocds-07smqs-1043398 [TME840315KT6, BD03FBE666C3DBA5C57BCDC8BF0AA451] | [TME840315KT6, BD03FBE666C3DBA5C57BCDC8BF0AA451] | [TME840315KT6, BD03FBE666C3DBA5C57BCDC8BF0AA451] | 2 | 2 | 2 | 1.000000 | True | [BD03FBE666C3DBA5C57BCDC8BF0AA451, TME840315KT6] | 2 | [] | SERVICIO MPLS ATRAVES DE UN ENLACE DEDICADO CO... | | 169133.00 | CIJ-66 | Centros de Integraci√≥n Juvenil, A.C. | CIJ731003QK3-012M7K001 | CIJ-Departamento de Adquisiciones #012M7K001 | 2016-04-18T12:02:38Z | . ocds-07smqs-1193763 [MLA840208FN5, D73016CAA1F8020E3BAC52068FB0B2D... | [D73016CAA1F8020E3BAC52068FB0B2D9, MLA840208FN5] | [MLA840208FN5, D73016CAA1F8020E3BAC52068FB0B2D... | 4 | 2 | 4 | 0.500000 | True | [MLA840208FN5, D73016CAA1F8020E3BAC52068FB0B2D9] | 2 | [] | ADQ. DE VIVERES PARA EJERCICIO 2017 | ADQ. DE VIVERES PARA EJERCICIO 2017 | 3880739.50 | IMSS-192 | Instituto Mexicano del Seguro Social | IMS421231I45-050GYR045 | IMSS-UMAE Hospital de Especilidades No.71 Dept... | 2016-12-09T05:26:28Z | . ocds-07smqs-1224403 [89E87098891F04A46318B7F775AD5E48, FAR100921AL... | [D73016CAA1F8020E3BAC52068FB0B2D9, MLA840208FN5] | [D73016CAA1F8020E3BAC52068FB0B2D9, 9D3346ADF0B... | 8 | 2 | 5 | 0.250000 | False | [MLA840208FN5, D73016CAA1F8020E3BAC52068FB0B2D9] | 2 | [FAR100921ALA, 89E87098891F04A46318B7F775AD5E4... | AA-019GYR026-E221-2016 DESIERTAS VIVERES | | 671930.69 | IMSS-192 | Instituto Mexicano del Seguro Social | IMS421231I45-050GYR026 | IMSS-Coordinaci√≥n de abastecimiento y equipami... | 2016-12-02T05:49:52Z | . ocds-07smqs-1240190 [RDO070228V11, ATD061228L34, MEX0301141G6] | [RDO070228V11, ATD061228L34] | [MEX0301141G6] | 3 | 2 | 1 | 0.666667 | True | [] | 0 | [RDO070228V11, ATD061228L34] | SERVICIO DE RESGUARDO, CUSTODIA, TRASLADO, ENV... | SERVICIO DE RESGUARDO, CUSTODIA, TRASLADO, ENV... | 116379.72 | CPTM-109 | Consejo de Promoci√≥n Tur√≠stica de M√©xico, S.A.... | CPT991022DE7-021W3J001 | CPTM-Gerencia de Adquisiciones y Licitaciones ... | 2016-12-20T06:52:52Z | . ocds-07smqs-1241959 [CGE130930JV2, CDA9601297G9, 23DF515587ED8B3F4... | [CDA9601297G9, 23DF515587ED8B3F4A8B1C9E4D725CAD] | [] | 3 | 2 | 0 | 0.666667 | True | [] | 0 | [CGE130930JV2, 23DF515587ED8B3F4A8B1C9E4D725CA... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . df_asoc = pd.read_pickle(f&#39;{dir_datos}/df_asociados.pkl&#39;) . ¬øEn cu√°ntos de estos casos los contratistas representaban el 50% de los proponentes o m√°s? | . print(&#39;Los contratistas representaban el 50% de los proponentes o m√°s en&#39;, df_asoc.part_mayo.sum(), &#39;licitaciones&#39;) . Los contratistas representaban el 50% de los proponentes o m√°s en 212 licitaciones . ¬øEn cu√°ntos de estos casos los asociados fueron los √∫nicos proponentes? | . print(&#39;¬øEn cu√°ntos de estos casos los asociados fueron los √∫nicos proponentes?&#39;, df_asoc.prop_asoc_part.eq(1).sum(), &#39;licitaciones&#39;) . ¬øEn cu√°ntos de estos casos los asociados fueron los √∫nicos proponentes? 41 licitaciones . De estos casos ¬øen cu√°ntas licitaciones los que estaban relacionados ganaron un concurso? | . print(&#39;En&#39;, df_asoc.N_asoc_ganadores.gt(0).sum(), &#39;licitaciones gan√≥ al menos uno de los contratistas asociados&#39;) . En 370 licitaciones gan√≥ al menos uno de los contratistas asociados . ¬øCu√°ntos contratistas asociados recibieron un contrato? | . print(df_asoc.N_asoc_ganadores.sum(), &#39; contratistas asociados ganaron una licitaci√≥n&#39;) . 552 contratistas asociados ganaron una licitaci√≥n . ¬øEn qu√© dependencias, unidades compradoras y servidores p√∫blicos ocurre m√°s esto? | . df_asoc.groupby([&#39;uc_name&#39;])[&#39;part&#39;].count().sort_values(ascending=False) . uc_name CONALITEG-Direcci√≥n de Recursos Materiales y Servicios Generales #011L6J001 33 IMSS-Departamento de Adquisici√≥n de Bienes y Contrataci√≥n de Servicios #050GYR033 16 IMSS-Coordinaci√≥n de Abastecimiento y Equipamiento #050GYR009 10 IMSS-Coordinaci√≥n de Adquisici√≥n de Bienes y Contrataci√≥n de Serv, Direcci√≥n de Administraci√≥n #050GYR047 9 INER-Departamento de Adquisiciones #012NCD001 9 .. IMSS-UMAE HOSPITAL DE GINECO OBSTETRICIA No 03 DR VICTOR MANUEL ESPINOSA DE LOS REYES SANCHEZ CMN LA RAZA #050GYR050 1 IMSS-Coord. de Abastecimiento y Equipamiento Deleg. Ver. Sur #050GYR022 1 SCT-Centro SCT Chihuahua #009000980 1 SCT-CENTRO SCT EN CHIAPAS SUBDIRECCION DE ADMINISTRACION #009000992 1 Tribunales Agrarios-Direcci√≥n General de Recursos Materiales #031000001 1 Name: part, Length: 218, dtype: int64 . df_asoc.groupby([&#39;dependencia_nombre&#39;])[&#39;part&#39;].count().sort_values(ascending=False) . dependencia_nombre Instituto Mexicano del Seguro Social 215 Comisi√≥n Nacional de Libros de Texto Gratuitos 33 Instituto de Seguridad y Servicios Sociales de los Trabajadores del Estado 32 Comisi√≥n Federal de Electricidad 24 Comisi√≥n Nacional del Agua 15 ... Hospital Regional de Alta Especialidad de Oaxaca 1 Exportadora de Sal, S.A. de C.V. 1 El Colegio de la Frontera Sur 1 Corporaci√≥n Mexicana de Investigaci√≥n en Materiales, S.A. de C.V. 1 Administraci√≥n Portuaria Integral de Progreso, S.A. de C.V. 1 Name: part, Length: 92, dtype: int64 . Crea red para visualizar . nodos = [] red = 1 for c, vals in df_asoc.iterrows(): nodos.append({&#39;id&#39;: c, &#39;tipo&#39;: &#39;contrato&#39;}) for p in vals[&#39;part_nogana&#39;]: nodos.append({&#39;id&#39;: p, &#39;tipo&#39;: &#39;tenderer&#39;}) links.append({&#39;origen_id&#39;: p, &#39;destino_id&#39;: c, &#39;accion&#39;: &#39;participa&#39;, &#39;red&#39;: red}) for p in vals[&#39;gana&#39;]: nodos.append({&#39;id&#39;: p, &#39;tipo&#39;: &#39;supplier&#39;}) links.append({&#39;origen_id&#39;: p, &#39;destino_id&#39;: c, &#39;accion&#39;: &#39;gana&#39;, &#39;red&#39;: red}) for p1 in vals[&#39;asoc&#39;]: for p2 in vals[&#39;asoc&#39;]: if p1!=p2: links.append({&#39;origen_id&#39;: p1, &#39;destino_id&#39;: p2, &#39;accion&#39;: &#39;asociado&#39;, &#39;red&#39;: red}) nodos.append({&#39;id&#39;: vals[&#39;uc_id&#39;], &#39;tipo&#39;: &#39;uc&#39;}) links.append({&#39;origen_id&#39;: vals[&#39;uc_id&#39;], &#39;destino_id&#39;: c, &#39;accion&#39;: &#39;compra&#39;, &#39;red&#39;: red}) red+=1 . df_nodos = pd.DataFrame(nodos) .assign(num=lambda x:x.index) dicc_nodo_num = {v:k for k,v in df_nodos[&#39;id&#39;].to_dict().items()} df_links = pd.DataFrame(links) .assign(origen_num=lambda x: x[&#39;origen_id&#39;].map(dicc_nodo_num), destino_num=lambda x: x[&#39;destino_id&#39;].map(dicc_nodo_num)) .dropna() df_links.head() . origen_id destino_id accion red origen_num destino_num . 25696 TME840315KT6 | ocds-07smqs-1043398 | gana | 1.0 | 287 | 0 | . 25697 BD03FBE666C3DBA5C57BCDC8BF0AA451 | ocds-07smqs-1043398 | gana | 1.0 | 286 | 0 | . 25698 TME840315KT6 | BD03FBE666C3DBA5C57BCDC8BF0AA451 | asociado | 1.0 | 287 | 286 | . 25699 BD03FBE666C3DBA5C57BCDC8BF0AA451 | TME840315KT6 | asociado | 1.0 | 286 | 287 | . 25700 CIJ731003QK3-012M7K001 | ocds-07smqs-1043398 | compra | 1.0 | 284 | 0 | . df_nodos.to_csv(&#39;datos/asociados_nodos.csv&#39;, index=False) df_links.to_csv(&#39;datos/asociados_links.csv&#39;, index=False) . Visualziacion networkX . df_nodos_graph = df_nodos.set_index(&#39;id&#39;) . for red in df_links.red.unique(): G = nx.from_pandas_edgelist(df_links.query(&#39;red==@red&#39;), source=&#39;origen_id&#39;, target=&#39;destino_id&#39;, edge_attr=[&#39;accion&#39;]) dicc_color_edges = {&#39;gana&#39;: &#39;green&#39;, &#39;asociado&#39;: &#39;red&#39;, &#39;participa&#39;: &#39;#3292a8&#39;, &#39;compra&#39;: &#39;orange&#39;} dicc_color_nodos = {&#39;contrato&#39;: &#39;#3292a8&#39;, &#39;supplier&#39;: &#39;pink&#39;, &#39;tenderer&#39;: &#39;blue&#39;, &#39;uc&#39;: &#39;orange&#39;} color_edges = [dicc_color_edges[e[2][&#39;accion&#39;]] for e in G.edges(data=True)] color_nodes = [dicc_color_nodos[df_nodos_graph.loc[[i], &#39;tipo&#39;].tolist()[0]] for i in G.nodes] fig, ax = plt.subplots() draw_network(G, color_edges=color_edges, color_nodes=color_nodes, axes=ax, labels=[1, 2, 4, 5], text_size=8) fig.savefig(f&#39;graficas/redes/red_{red}.png&#39;, dpi=200) plt.cla() . print(df_asoc.loc[[x for x in df_links.query(&#39;red==@red&#39;)[&#39;destino_id&#39;].unique() if &#39;ocds&#39; in x][0]]) . Tareas: . Procesar telefonos . | procesar m√∫ltiples mails . | Es posible obtener m√°s datos de los contratistas a partir del RUCP, como el sitio web, giro del negocio . | . Buscar otra anomal√≠a: todos los contratos con m√©todos abiertos en los que solo participa un proponente. Buscar contratos en los que todos los particpantes reciben contrato. . Buscar otra anomal√≠a: todos los contratos con m√©todos abiertos en los que solo participa un proponente. | Buscar contratos en los que todos los particpantes reciben contrato. | . Funcionarios que intervienen en contrataciones . mydb.func_contrat.count_documents({}) . 113795 . mydb.func_contrat.find_one() . {&#39;_id&#39;: ObjectId(&#39;5deb255d723b95da59c6a01b&#39;), &#39;id&#39;: &#39;c6dbd706-b539-476f-a400-4dd69ed4a757&#39;, &#39;fechaCaptura&#39;: &#39;&#39;, &#39;ejercicioFiscal&#39;: 2017, &#39;periodoEjercicio&#39;: {&#39;fechaInicial&#39;: &#39;2017/01/01&#39;, &#39;fechaFinal&#39;: &#39;2017/12/31&#39;}, &#39;idRamo&#39;: 6, &#39;ramo&#39;: &#39;HACIENDA Y CR√âDITO P√öBLICO&#39;, &#39;nombres&#39;: None, &#39;primerApellido&#39;: None, &#39;segundoApellido&#39;: None, &#39;genero&#39;: None, &#39;institucionDependencia&#39;: {&#39;siglas&#39;: &#39;CNBV&#39;, &#39;nombre&#39;: &#39;COMISI√ìN NACIONAL BANCARIA Y DE VALORES&#39;, &#39;clave&#39;: &#39;6/B00&#39;}, &#39;puesto&#39;: {&#39;nombre&#39;: &#39;SUBDIRECTOR DE MEJORA A&#39;, &#39;nivel&#39;: None}, &#39;tipoArea&#39;: [&#39;R&#39;], &#39;nivelResponsabilidad&#39;: [&#39;A&#39;, &#39;T&#39;], &#39;tipoProcedimiento&#39;: 1, &#39;tipoActos&#39;: &#39;CONTRATACIONES&#39;, &#39;superiorInmediato&#39;: {&#39;nombres&#39;: None, &#39;primerApellido&#39;: None, &#39;segundoApellido&#39;: None, &#39;puesto&#39;: {&#39;nombre&#39;: None, &#39;nivel&#39;: None}}} . nombre_func_contrat = [f&#39;{r[&quot;nombres&quot;]} {r[&quot;primerApellido&quot;]} {r[&quot;segundoApellido&quot;]}&#39; for r in mydb.func_contrat.find({}, {&#39;_id&#39;:0, &#39;nombres&#39;: 1, &#39;primerApellido&#39;: 1, &#39;segundoApellido&#39;:1}) if all([r[&quot;nombres&quot;], r[&quot;primerApellido&quot;], r[&quot;segundoApellido&quot;]])] . Funcionarios sancionados . mydb.serv_sanc.count_documents({}) . 3575 . mydb.serv_sanc.find_one() . {&#39;_id&#39;: ObjectId(&#39;5deb27a2432e395ca7ba4a62&#39;), &#39;nombres&#39;: &#39;ZACARIAS&#39;, &#39;primerApellido&#39;: &#39;PEREZ&#39;, &#39;segundoApellido&#39;: &#39;GARCIA&#39;, &#39;institucionDependencia&#39;: {&#39;nombre&#39;: &#39;PROCURADURIA GENERAL DE LA REPUBLICA&#39;, &#39;siglas&#39;: &#39; &#39;}, &#39;autoridadSancionadora&#39;: &#39;ORGANO INTERNO DE CONTROL&#39;, &#39;expediente&#39;: &#39;520/99&#39;, &#39;resolucion&#39;: {&#39;fechaResolucion&#39;: &#39;17/11/2000&#39;}, &#39;tipoSancion&#39;: &#39;INHABILITACION&#39;, &#39;inhabilitacion&#39;: {&#39;fechaInicial&#39;: &#39;17/11/2000&#39;, &#39;fechaFinal&#39;: &#39;16/11/2020&#39;, &#39;observaciones&#39;: None}, &#39;multa&#39;: {&#39;monto&#39;: None, &#39;moneda&#39;: &#39;MXN&#39;}, &#39;causaMotivoHechos&#39;: &#39;ABUSO DE AUTORIDAD&#39;, &#39;puesto&#39;: &#39;AGENTE DE LA POLICIA JUDICIAL FEDERAL&#39;} . nombre_serv_sanc = [f&#39;{r[&quot;nombres&quot;]} {r[&quot;primerApellido&quot;]} {r[&quot;segundoApellido&quot;]}&#39; for r in mydb.serv_sanc.find({}, {&#39;_id&#39;:0, &#39;nombres&#39;: 1, &#39;primerApellido&#39;: 1, &#39;segundoApellido&#39;:1})] . casos_func = [p[&#39;contactPoint&#39;][&#39;name&#39;] for c in casos_contratos for p in c[&#39;parties&#39;] if p[&#39;roles&#39;]==[&#39;procuringEntity&#39;]] . set(casos_func).intersection(set(nombre_serv_sanc)) . set() . yt = list(set(df_contactos.name.unique().tolist()).intersection(set(nombre_serv_sanc))) len(yt) . 10 . yt . [&#39;MIGUEL ANGEL TORRES HERNANDEZ&#39;, &#39;AGUSTIN TOLEDO GADEA&#39;, &#39;OSCAR CHAVEZ MARTINEZ&#39;, &#39;JOSE LUIS CHAVEZ FLORES&#39;, &#39;MARIO HERNANDEZ DIAZ&#39;, &#39;RODRIGO MALDONADO SAHAGUN&#39;, &#39;ERIKA BENITEZ GARCIA&#39;, &#39;FRANCISCO FIERRO SILVA&#39;, &#39;JOSE LUIS GARCIA RODRIGUEZ&#39;, &#39;JOSE DE LA CRUZ RAMIREZ&#39;] . Particulares sancionados . mydb.part_sanc.count_documents({}) . 1853 . mydb.part_sanc.find_one() . {&#39;_id&#39;: ObjectId(&#39;5deb27d0715998a251b6be6b&#39;), &#39;fechaCaptura&#39;: &#39;2019-08-22&#39;, &#39;expediente&#39;: &#39;000270074/2017&#39;, &#39;nombreRazonSocial&#39;: &#39;CONSTRUCCI√ìN ESPECIALIZADA Y TECNOL√ìGICA DE M√âXICO, S.A. DE C.V.&#39;, &#39;rfc&#39;: &#39;ACV990407&#39;, &#39;telefono&#39;: &#39;01 961 61 5 30 09&#39;, &#39;domicilio&#39;: {&#39;clave&#39;: &#39;MX&#39;}, &#39;tipoSancion&#39;: &#39;ECONOMICA E INHABILITACI√ìN&#39;, &#39;institucionDependencia&#39;: {&#39;nombre&#39;: &#39;SECRETARIA DE LA FUNCI√ìN P√öBLICA&#39;, &#39;siglas&#39;: &#39;SFP&#39;}, &#39;tipoFalta&#39;: &#39;&#39;, &#39;causaMotivoHechos&#39;: &#39;NO ENTREGAR LA OBRA EN LA FECHA COMPROMETIDA PARA ELLO, ESTO ES EL 24 DE SEPTIEMBRE DE 2014&#39;, &#39;objetoContrato&#39;: &#39;&#39;, &#39;autoridadSancionadora&#39;: &#39;SECRETARIA DE LA FUNCI√ìN P√öBLICA&#39;, &#39;responsableSancion&#39;: {&#39;nombres&#39;: &#39;MAR√çA GUADALUPE VARGAS √ÅLVAREZ&#39;, &#39;primerApellido&#39;: &#39;&#39;, &#39;segundoApellido&#39;: &#39;&#39;}, &#39;resolucion&#39;: {&#39;sentido&#39;: &#39;SANCIONATORIA CON MULTA E INHABILITACI√ìN&#39;}, &#39;fechaNotificacion&#39;: &#39;2019-08-14&#39;, &#39;multa&#39;: {&#39;monto&#39;: &#39;504675.00&#39;, &#39;moneda&#39;: &#39;MXN&#39;}, &#39;plazo&#39;: {&#39;fechaInicial&#39;: &#39;2019-08-23&#39;}, &#39;observaciones&#39;: None} . rfc_sanc = [r[&#39;rfc&#39;] for r in mydb.part_sanc.find({&#39;rfc&#39;: {&#39;$ne&#39;: &#39;&#39;}}, {&#39;_id&#39;:0, &#39;rfc&#39;: 1})] . Red Mitchell . result1 = mydb.contrataciones.find({&#39;contracts&#39;: {&#39;$exists&#39;: True}}, [&#39;ocid&#39;, &#39;parties.id&#39;, &#39;parties.roles&#39;, &#39;parties.contactPoint&#39;, &#39;contracts.value.amount&#39;, &#39;date&#39;]) l1 = list(result1) . ocid_tenderer = pd.DataFrame([(c[&#39;ocid&#39;], p[&#39;id&#39;]) for c in l1 for p in c[&#39;parties&#39;] if p[&#39;roles&#39;] in [[&#39;tenderer&#39;, &#39;supplier&#39;], [&#39;tenderer&#39;]]], columns=[&#39;ocid&#39;, &#39;tenderer_id&#39;], ).set_index(&#39;ocid&#39;) ocid_tenderer.head() . tenderer_id . ocid . ocds-07smqs-1003803 E9C1C827AE1234CCF7AC4D9070BB597C | . ocds-07smqs-1003123 SCA031118BX7 | . ocds-07smqs-1003123 SAU0505307M9 | . ocds-07smqs-1003123 SCK070618C21 | . ocds-07smqs-1009245 R&amp;S811221KR6 | . ocid_funcionario = pd.DataFrame([(c[&#39;ocid&#39;], p[&#39;contactPoint&#39;].get(&#39;name&#39;, &#39;&#39;), p[&#39;id&#39;], c[&#39;contracts&#39;][0][&#39;value&#39;][&#39;amount&#39;], c[&#39;date&#39;]) for c in l1 for p in c[&#39;parties&#39;] if p[&#39;roles&#39;]==[&#39;procuringEntity&#39;]], columns=[&#39;ocid&#39;, &#39;funcionario_id&#39;, &#39;uc_id&#39;, &#39;valor_contrato&#39;, &#39;fecha&#39;]) .set_index(&#39;ocid&#39;) ocid_dependencia = pd.DataFrame([(c[&#39;ocid&#39;], p[&#39;id&#39;]) for c in l1 for p in c[&#39;parties&#39;] if p[&#39;roles&#39;]==[&#39;buyer&#39;]], columns=[&#39;ocid&#39;, &#39;dep_id&#39;]) .set_index(&#39;ocid&#39;) ocid_funcionario.head() . funcionario_id uc_id valor_contrato fecha . ocid . ocds-07smqs-1003803 Jos√© Gabriel Ramos Mart√≠nez | SAT970701NN3-006E00002 | 8451072.00 | 2016-02-19T01:09:18Z | . ocds-07smqs-1003123 Ignacio Romero S√°nchez | PGR850101RC6-017000017 | 168000.00 | 2016-02-19T01:49:22Z | . ocds-07smqs-1009245 Juan Fernando Meza Zavala | STP401231P53-014000999 | 420689.55 | 2016-02-26T05:33:08Z | . ocds-07smqs-1012355 Luis Eduardo Vega Becerra | CNU800928K31-018E00999 | 20000.00 | 2016-03-02T01:58:39Z | . ocds-07smqs-1025654 Marco Antonio Brito Vidales | IAA6210025R4-006A00996 | 10604000.00 | 2016-03-18T06:40:28Z | . ocid_tender_fun = ocid_tenderer.join([ocid_funcionario, ocid_dependencia]) ocid_tender_fun . tenderer_id funcionario_id uc_id valor_contrato fecha dep_id . ocid . ocds-07smqs-1001024 ELE9012281G2 | Evelyn L√≥pez Valverde | LIC950821M84-020VST003 | 1.152540e+05 | 2016-03-15T01:02:50Z | LICONSA-231 | . ocds-07smqs-1001040 HIG090519H30 | Nicolas Gonzalez Bustos | HIM871203BS0-012NBG001 | 2.603075e+07 | 2016-02-16T02:44:58Z | HIM-163 | . ocds-07smqs-1001984 282910F3163E9D7DBC543E53CD9347B6 | Nicolas Gonzalez Bustos | HIM871203BS0-012NBG001 | 1.071380e+05 | 2016-02-17T04:42:35Z | HIM-163 | . ocds-07smqs-1002362 IPS040121S66 | Nicolas Gonzalez Bustos | HIM871203BS0-012NBG001 | 2.115000e+05 | 2016-02-17T07:30:57Z | HIM-163 | . ocds-07smqs-1003123 SCA031118BX7 | Ignacio Romero S√°nchez | PGR850101RC6-017000017 | 1.680000e+05 | 2016-02-19T01:49:22Z | PGR-251 | . ... ... | ... | ... | ... | ... | ... | . ocds-07smqs-999514 CPC131113AT4 | Luis Enrique Mendoza Flores | IMS421231I45-050GYR026 | 7.317600e+04 | 2016-02-12T01:34:46Z | IMSS-192 | . ocds-07smqs-999514 96A74A55F4E5DAEC0797B59049D8EC81 | Luis Enrique Mendoza Flores | IMS421231I45-050GYR026 | 7.317600e+04 | 2016-02-12T01:34:46Z | IMSS-192 | . ocds-07smqs-999514 TGH130612IK1 | Luis Enrique Mendoza Flores | IMS421231I45-050GYR026 | 7.317600e+04 | 2016-02-12T01:34:46Z | IMSS-192 | . ocds-07smqs-999514 SIN011023UC8 | Luis Enrique Mendoza Flores | IMS421231I45-050GYR026 | 7.317600e+04 | 2016-02-12T01:34:46Z | IMSS-192 | . ocds-07smqs-999514 GMC09121623A | Luis Enrique Mendoza Flores | IMS421231I45-050GYR026 | 7.317600e+04 | 2016-02-12T01:34:46Z | IMSS-192 | . 726038 rows √ó 6 columns . ocid_tender_fun.to_csv(f&#39;{dir_datos}/ocid_tender_fun.csv&#39;) .",
            "url": "http://blog.jjsantoso.com/analisis%20de%20datos/pandas/pymongo/2020/01/20/redes-contratos-compranet.html",
            "relUrl": "/analisis%20de%20datos/pandas/pymongo/2020/01/20/redes-contratos-compranet.html",
            "date": " ‚Ä¢ Jan 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Bio",
          "content": ". Soy un economista apasionado por el an√°lisis de datos, la estad√≠stica y la visualizaci√≥n. Trabajo en la Unidad de Ciencia de Datos del Laboratorio Nacional de Pol√≠ticas P√∫blicas del CIDE donde hacemos an√°lisis de datos para temas de pol√≠ticas p√∫blicas. A veces doy cursos de Python. A veces participo en datatones. Aqu√≠ pueden conocer algo de los proyectos personales en los que me gusta trabajar. . Soy de Cartagena (Colombia) y vivo en la Ciudad de M√©xico. Me gusta el monta√±ismo y conocer la riqueza natural y cultural de M√©xico. . Me encuentran en Twitter como @jjsantoso y aqu√≠ est√° mi perfil en LinkedIn. Pueden consultar aqu√≠ mi CV o tambi√©n revisar mi cuenta de GitHub. .",
          "url": "http://blog.jjsantoso.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "http://blog.jjsantoso.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}